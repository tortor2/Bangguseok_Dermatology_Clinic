{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM0QWbX1tAdQWyrGaDCI+QQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tajEOLfladBP","executionInfo":{"status":"ok","timestamp":1763950210162,"user_tz":-540,"elapsed":23,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"f2ade921-db6f-404b-c36e-2dfa1cc07abe"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","처리 중: /content/final_knowledge_chunks_for_embedding.jsonl\n","  84개 문서 처리 완료\n","\n","처리 중: /content/kb_docs_chunked.jsonl\n","  129개 문서 처리 완료\n","\n","처리 중: /content/raft_dataset.jsonl\n","  132개 문서 처리 완료\n","\n","document_type 최종 처리 중...\n","\n","총 345개 문서를 'merged_output.jsonl'에 저장했습니다.\n","\n","=== 통계 ===\n","\n","Label별 문서 수:\n","  Acne: 67개\n","  Atopic: 36개\n","  Atopic dermatitis: 15개\n","  Eczema: 11개\n","  Folliculitis: 15개\n","  Normal: 3개\n","  Psoriasis: 45개\n","  Rosacea: 34개\n","  Seborrheic: 21개\n","  Seborrheic dermatitis: 15개\n","  Tinea: 14개\n","  Urticaria: 14개\n","  Vitiligo: 28개\n","  Wart: 27개\n","\n","Document type별 문서 수:\n","  oracle: 233개\n","  distractor: 112개\n","  none: 0개\n","\n","=== 결과 샘플 (처음 3개) ===\n","\n","문서 1:\n","  source: MSD Manual\n","  label: Acne\n","  title: 여드름의 원인\n","  text: 여드름은 모낭(모발이 자라는 피부의 구멍)의 염증을 일으키는 호르몬, 피지, 세균 간의 상...\n","  text_length: 670\n","  document_type: oracle\n","\n","문서 2:\n","  source: MSD Manual\n","  label: Acne\n","  title: 여드름의 원인\n","  text: 에서 흔히 발견되는 세균인 모낭관 내 여드름균(이전 여드름 유발균)의 과다증식을 촉진합니다...\n","  text_length: 180\n","  document_type: oracle\n","\n","문서 3:\n","  source: MSD Manual\n","  label: Acne\n","  title: 여드름의 원인\n","  text: 사춘기 여드름은 특히 안드로겐(테스토스테론 등) 등의 호르몬 증가로 인해 피지선이 자극되어...\n","  text_length: 662\n","  document_type: oracle\n"]}],"source":["import json\n","\n","def process_and_merge_jsonl_files(file1, file2, file3, output_file):\n","    \"\"\"\n","    3개의 JSONL 파일을 읽어서 공통 구조로 변환 후 하나로 합치는 함수\n","    \"\"\"\n","    all_documents = []\n","\n","    # Oracle로 분류될 label 목록\n","    oracle_labels = {\n","        \"Psoriasis\", \"Seborrheic Dermatitis\", \"Seborrheic\",\n","        \"Rosacea\", \"Acne\", \"Atopic Dermatitis\", \"Atopic\"\n","    }\n","\n","    # 각 파일 처리\n","    for file_path in [file1, file2, file3]:\n","        print(f\"\\n처리 중: {file_path}\")\n","\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            doc_count = 0\n","            for line_num, line in enumerate(f):\n","                if not line.strip():\n","                    continue\n","\n","                try:\n","                    doc = json.loads(line)\n","                    processed_doc = {}\n","\n","                    # 1. source 유지\n","                    processed_doc['source'] = doc.get('source', '')\n","\n","                    # 2. label 첫 글자 대문자로 변경\n","                    label = doc.get('label', '')\n","                    processed_doc['label'] = label.capitalize()\n","\n","                    # 3. title 처리\n","                    if 'section' in doc:  # 1,2번 파일\n","                        processed_doc['title'] = doc['section']\n","                    elif 'title' in doc:  # 3번 파일\n","                        processed_doc['title'] = doc['title']\n","                    else:\n","                        processed_doc['title'] = ''\n","\n","                    # 4. text 처리\n","                    if 'text' in doc:  # 1,2번 파일\n","                        processed_doc['text'] = doc['text']\n","                    elif 'content' in doc:  # 3번 파일\n","                        processed_doc['text'] = doc['content']\n","                    else:\n","                        processed_doc['text'] = ''\n","\n","                    # 5. text_length 처리\n","                    if 'text_length' in doc:\n","                        processed_doc['text_length'] = doc['text_length']\n","                    else:\n","                        processed_doc['text_length'] = len(processed_doc['text'])\n","\n","                    # 6. document_type 처리 (임시로 저장, 나중에 처리)\n","                    processed_doc['_original_doc_type'] = doc.get('document_type', None)\n","\n","                    all_documents.append(processed_doc)\n","                    doc_count += 1\n","\n","                except json.JSONDecodeError as e:\n","                    print(f\"  줄 {line_num + 1} 파싱 에러: {e}\")\n","\n","            print(f\"  {doc_count}개 문서 처리 완료\")\n","\n","    # 7. 모든 문서에 대해 document_type 최종 처리\n","    print(\"\\ndocument_type 최종 처리 중...\")\n","    for doc in all_documents:\n","        if doc['_original_doc_type'] is not None:\n","            # 기존 document_type이 있으면 유지\n","            doc['document_type'] = doc['_original_doc_type']\n","        else:\n","            # 없으면 label에 따라 설정\n","            if doc['label'] in oracle_labels:\n","                doc['document_type'] = 'oracle'\n","            else:\n","                doc['document_type'] = 'distractor'\n","\n","        # 임시 필드 제거\n","        del doc['_original_doc_type']\n","\n","    # 8. 결과를 하나의 JSONL 파일로 저장\n","    with open(output_file, 'w', encoding='utf-8') as f:\n","        for doc in all_documents:\n","            json.dump(doc, f, ensure_ascii=False)\n","            f.write('\\n')\n","\n","    print(f\"\\n총 {len(all_documents)}개 문서를 '{output_file}'에 저장했습니다.\")\n","\n","    # 통계 출력\n","    print(\"\\n=== 통계 ===\")\n","    label_counts = {}\n","    doc_type_counts = {'oracle': 0, 'distractor': 0, 'none': 0}\n","\n","    for doc in all_documents:\n","        # Label별 카운트\n","        label = doc['label']\n","        label_counts[label] = label_counts.get(label, 0) + 1\n","\n","        # Document type별 카운트\n","        doc_type = doc.get('document_type', 'none')\n","        if doc_type in doc_type_counts:\n","            doc_type_counts[doc_type] += 1\n","        else:\n","            doc_type_counts[doc_type] = doc_type_counts.get(doc_type, 0) + 1\n","\n","    print(\"\\nLabel별 문서 수:\")\n","    for label, count in sorted(label_counts.items()):\n","        print(f\"  {label}: {count}개\")\n","\n","    print(\"\\nDocument type별 문서 수:\")\n","    for doc_type, count in doc_type_counts.items():\n","        print(f\"  {doc_type}: {count}개\")\n","\n","    return all_documents\n","\n","# 사용 예시\n","if __name__ == \"__main__\":\n","    # 3개의 JSONL 파일 경로 지정\n","    file1 = \"/content/final_knowledge_chunks_for_embedding.jsonl\"  # 첫 번째 JSONL 파일\n","    file2 = \"/content/kb_docs_chunked.jsonl\"  # 두 번째 JSONL 파일\n","    file3 = \"/content/raft_dataset.jsonl\"  # 세 번째 JSONL 파일 (labeled_output.jsonl)\n","\n","    # 통합된 출력 파일\n","    output = \"merged_output.jsonl\"\n","\n","    # 처리 실행\n","    merged_data = process_and_merge_jsonl_files(file1, file2, file3, output)\n","\n","    # 결과 샘플 확인\n","    print(\"\\n=== 결과 샘플 (처음 3개) ===\")\n","    for i, doc in enumerate(merged_data[:3]):\n","        print(f\"\\n문서 {i+1}:\")\n","        for key, value in doc.items():\n","            if key == 'text':\n","                print(f\"  {key}: {value[:50]}...\")\n","            else:\n","                print(f\"  {key}: {value}\")"]},{"cell_type":"code","source":["import json\n","\n","def update_labels_in_jsonl(input_file, output_file):\n","    \"\"\"\n","    JSONL 파일의 label 값을 업데이트하는 함수\n","    - Seborrheic → Seborrheic Dermatitis\n","    - Seborrheic dermatitis → Seborrheic Dermatitis\n","    - Atopic → Atopic Dermatitis\n","    - Atopic dermatitis → Atopic Dermatitis\n","    \"\"\"\n","    # 변경할 label 매핑 (대소문자 구분 없이 처리하기 위해 lower case도 포함)\n","    label_mapping = {\n","        \"Seborrheic\": \"Seborrheic Dermatitis\",\n","        \"Seborrheic dermatitis\": \"Seborrheic Dermatitis\",\n","        \"Seborrheic Dermatitis\": \"Seborrheic Dermatitis\",  # 이미 올바른 형식이어도 통일성을 위해\n","        \"Atopic\": \"Atopic Dermatitis\",\n","        \"Atopic dermatitis\": \"Atopic Dermatitis\",\n","        \"Atopic Dermatitis\": \"Atopic Dermatitis\"  # 이미 올바른 형식이어도 통일성을 위해\n","    }\n","\n","    updated_count = 0\n","    total_count = 0\n","    label_changes = {}\n","\n","    print(f\"파일 처리 중: {input_file}\")\n","\n","    # 읽고 쓰기\n","    with open(input_file, 'r', encoding='utf-8') as f_in, \\\n","         open(output_file, 'w', encoding='utf-8') as f_out:\n","\n","        for line_num, line in enumerate(f_in):\n","            if not line.strip():\n","                continue\n","\n","            try:\n","                doc = json.loads(line)\n","                total_count += 1\n","\n","                # label이 있는 경우\n","                if 'label' in doc:\n","                    old_label = doc['label']\n","\n","                    # 변경이 필요한 경우\n","                    if old_label in label_mapping:\n","                        new_label = label_mapping[old_label]\n","\n","                        # 실제로 변경이 일어나는 경우만 카운트\n","                        if old_label != new_label:\n","                            doc['label'] = new_label\n","                            updated_count += 1\n","\n","                            # 변경 내역 기록\n","                            if old_label not in label_changes:\n","                                label_changes[old_label] = 0\n","                            label_changes[old_label] += 1\n","\n","                # 수정된(또는 원본) 문서를 출력 파일에 쓰기\n","                json.dump(doc, f_out, ensure_ascii=False)\n","                f_out.write('\\n')\n","\n","            except json.JSONDecodeError as e:\n","                print(f\"줄 {line_num + 1} 파싱 에러: {e}\")\n","                # 파싱 에러가 난 줄은 원본 그대로 복사\n","                f_out.write(line)\n","\n","    # 결과 출력\n","    print(f\"\\n=== Label 업데이트 결과 ===\")\n","    print(f\"총 처리된 문서 수: {total_count}\")\n","    print(f\"업데이트된 문서 수: {updated_count}\")\n","\n","    if label_changes:\n","        print(f\"\\n변경 내역:\")\n","        for old_label, count in sorted(label_changes.items()):\n","            new_label = label_mapping[old_label]\n","            print(f\"  '{old_label}' → '{new_label}': {count}개\")\n","    else:\n","        print(\"\\n변경된 label이 없습니다.\")\n","\n","    print(f\"\\n결과가 '{output_file}'에 저장되었습니다.\")\n","\n","    return updated_count\n","\n","def check_labels_before_after(input_file, output_file):\n","    \"\"\"\n","    변경 전후의 label을 비교하는 함수\n","    \"\"\"\n","    def get_label_counts(file_path):\n","        label_counts = {}\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            for line in f:\n","                if line.strip():\n","                    try:\n","                        doc = json.loads(line)\n","                        if 'label' in doc:\n","                            label = doc['label']\n","                            label_counts[label] = label_counts.get(label, 0) + 1\n","                    except:\n","                        pass\n","        return label_counts\n","\n","    print(\"\\n=== Label 변경 전후 비교 ===\")\n","\n","    # 변경 전\n","    before_counts = get_label_counts(input_file)\n","    print(\"\\n변경 전 label 목록:\")\n","    for label in sorted(before_counts.keys()):\n","        print(f\"  {label}: {before_counts[label]}개\")\n","\n","    # 변경 후\n","    after_counts = get_label_counts(output_file)\n","    print(\"\\n변경 후 label 목록:\")\n","    for label in sorted(after_counts.keys()):\n","        print(f\"  {label}: {after_counts[label]}개\")\n","\n","    # 변경 확인\n","    target_labels = [\"Seborrheic\", \"Seborrheic dermatitis\", \"Atopic\", \"Atopic dermatitis\"]\n","    remaining = [label for label in target_labels if label in after_counts]\n","\n","    if remaining:\n","        print(f\"\\n⚠️ 아직 변경되지 않은 label: {remaining}\")\n","    else:\n","        print(\"\\n✅ 모든 대상 label이 성공적으로 통합되었습니다.\")\n","\n","# 사용 예시\n","if __name__ == \"__main__\":\n","    # 입력 파일과 출력 파일 지정\n","    input_jsonl = \"merged_output.jsonl\"  # 원본 파일\n","    output_jsonl = \"updated_labels_final.jsonl\"  # 업데이트된 파일\n","\n","    # Label 업데이트 실행\n","    update_labels_in_jsonl(input_jsonl, output_jsonl)\n","\n","    # 변경 전후 비교\n","    check_labels_before_after(input_jsonl, output_jsonl)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dkEQRhG7rOXt","executionInfo":{"status":"ok","timestamp":1763951051352,"user_tz":-540,"elapsed":8,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"d0fbc958-5732-47b1-dfa4-baebd1404f50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["파일 처리 중: merged_output.jsonl\n","\n","=== Label 업데이트 결과 ===\n","총 처리된 문서 수: 345\n","업데이트된 문서 수: 87\n","\n","변경 내역:\n","  'Atopic' → 'Atopic Dermatitis': 36개\n","  'Atopic dermatitis' → 'Atopic Dermatitis': 15개\n","  'Seborrheic' → 'Seborrheic Dermatitis': 21개\n","  'Seborrheic dermatitis' → 'Seborrheic Dermatitis': 15개\n","\n","결과가 'updated_labels_final.jsonl'에 저장되었습니다.\n","\n","=== Label 변경 전후 비교 ===\n","\n","변경 전 label 목록:\n","  Acne: 67개\n","  Atopic: 36개\n","  Atopic dermatitis: 15개\n","  Eczema: 11개\n","  Folliculitis: 15개\n","  Normal: 3개\n","  Psoriasis: 45개\n","  Rosacea: 34개\n","  Seborrheic: 21개\n","  Seborrheic dermatitis: 15개\n","  Tinea: 14개\n","  Urticaria: 14개\n","  Vitiligo: 28개\n","  Wart: 27개\n","\n","변경 후 label 목록:\n","  Acne: 67개\n","  Atopic Dermatitis: 51개\n","  Eczema: 11개\n","  Folliculitis: 15개\n","  Normal: 3개\n","  Psoriasis: 45개\n","  Rosacea: 34개\n","  Seborrheic Dermatitis: 36개\n","  Tinea: 14개\n","  Urticaria: 14개\n","  Vitiligo: 28개\n","  Wart: 27개\n","\n","✅ 모든 대상 label이 성공적으로 통합되었습니다.\n"]}]},{"cell_type":"code","source":["import json\n","from collections import Counter\n","\n","def analyze_labels_in_jsonl(file_path):\n","    \"\"\"\n","    JSONL 파일을 읽어서 label의 종류와 각 label별 개수를 분석하는 함수\n","    \"\"\"\n","    labels = []\n","    total_docs = 0\n","    error_count = 0\n","    no_label_count = 0\n","\n","    print(f\"분석 중: {file_path}\\n\")\n","\n","    # JSONL 파일 읽기\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        for line_num, line in enumerate(f):\n","            if not line.strip():\n","                continue\n","\n","            try:\n","                doc = json.loads(line)\n","                total_docs += 1\n","\n","                # label 키가 있는지 확인\n","                if 'label' in doc:\n","                    labels.append(doc['label'])\n","                else:\n","                    no_label_count += 1\n","\n","            except json.JSONDecodeError as e:\n","                error_count += 1\n","                print(f\"줄 {line_num + 1} 파싱 에러: {e}\")\n","\n","    # label별 개수 카운트\n","    label_counts = Counter(labels)\n","\n","    # 결과 출력\n","    print(\"=== Label 분석 결과 ===\")\n","    print(f\"총 문서 수: {total_docs}\")\n","    print(f\"label이 있는 문서 수: {len(labels)}\")\n","    print(f\"label이 없는 문서 수: {no_label_count}\")\n","    print(f\"파싱 에러 수: {error_count}\")\n","\n","    print(f\"\\n총 {len(label_counts)}개의 고유한 label이 발견되었습니다.\")\n","\n","    # label별 개수 출력 (많은 순서대로)\n","    print(\"\\n=== Label별 문서 개수 (많은 순) ===\")\n","    for label, count in label_counts.most_common():\n","        percentage = (count / len(labels) * 100) if len(labels) > 0 else 0\n","        print(f\"{label}: {count}개 ({percentage:.1f}%)\")\n","\n","    # 알파벳 순서로도 출력\n","    print(\"\\n=== Label별 문서 개수 (알파벳 순) ===\")\n","    for label in sorted(label_counts.keys()):\n","        count = label_counts[label]\n","        percentage = (count / len(labels) * 100) if len(labels) > 0 else 0\n","        print(f\"{label}: {count}개 ({percentage:.1f}%)\")\n","\n","    return label_counts\n","\n","def save_label_analysis(file_path, output_path):\n","    \"\"\"\n","    Label 분석 결과를 텍스트 파일로 저장하는 함수\n","    \"\"\"\n","    label_counts = analyze_labels_in_jsonl(file_path)\n","\n","    with open(output_path, 'w', encoding='utf-8') as f:\n","        f.write(f\"Label 분석 결과 - {file_path}\\n\")\n","        f.write(\"=\" * 50 + \"\\n\\n\")\n","\n","        f.write(f\"총 고유 label 수: {len(label_counts)}\\n\")\n","        f.write(f\"총 문서 수: {sum(label_counts.values())}\\n\\n\")\n","\n","        f.write(\"Label별 개수 (많은 순):\\n\")\n","        f.write(\"-\" * 30 + \"\\n\")\n","        for label, count in label_counts.most_common():\n","            percentage = (count / sum(label_counts.values()) * 100)\n","            f.write(f\"{label}: {count}개 ({percentage:.1f}%)\\n\")\n","\n","        f.write(\"\\n\\nLabel별 개수 (알파벳 순):\\n\")\n","        f.write(\"-\" * 30 + \"\\n\")\n","        for label in sorted(label_counts.keys()):\n","            count = label_counts[label]\n","            percentage = (count / sum(label_counts.values()) * 100)\n","            f.write(f\"{label}: {count}개 ({percentage:.1f}%)\\n\")\n","\n","    print(f\"\\n분석 결과가 '{output_path}'에 저장되었습니다.\")\n","\n","# 사용 예시\n","if __name__ == \"__main__\":\n","    # 분석할 JSONL 파일 경로\n","    jsonl_file = \"merged_output.jsonl\"  # 실제 파일명으로 변경\n","\n","    # 기본 분석\n","    label_stats = analyze_labels_in_jsonl(jsonl_file)\n","\n","    # 분석 결과를 파일로 저장하고 싶다면\n","    # save_label_analysis(jsonl_file, \"label_analysis.txt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EkqxgOS4pANX","executionInfo":{"status":"ok","timestamp":1763950524978,"user_tz":-540,"elapsed":16,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"10435ded-f7a3-4853-9d12-9f1ff0bdf0e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["분석 중: merged_output.jsonl\n","\n","=== Label 분석 결과 ===\n","총 문서 수: 345\n","label이 있는 문서 수: 345\n","label이 없는 문서 수: 0\n","파싱 에러 수: 0\n","\n","총 14개의 고유한 label이 발견되었습니다.\n","\n","=== Label별 문서 개수 (많은 순) ===\n","Acne: 67개 (19.4%)\n","Psoriasis: 45개 (13.0%)\n","Atopic: 36개 (10.4%)\n","Rosacea: 34개 (9.9%)\n","Vitiligo: 28개 (8.1%)\n","Wart: 27개 (7.8%)\n","Seborrheic: 21개 (6.1%)\n","Atopic dermatitis: 15개 (4.3%)\n","Seborrheic dermatitis: 15개 (4.3%)\n","Folliculitis: 15개 (4.3%)\n","Tinea: 14개 (4.1%)\n","Urticaria: 14개 (4.1%)\n","Eczema: 11개 (3.2%)\n","Normal: 3개 (0.9%)\n","\n","=== Label별 문서 개수 (알파벳 순) ===\n","Acne: 67개 (19.4%)\n","Atopic: 36개 (10.4%)\n","Atopic dermatitis: 15개 (4.3%)\n","Eczema: 11개 (3.2%)\n","Folliculitis: 15개 (4.3%)\n","Normal: 3개 (0.9%)\n","Psoriasis: 45개 (13.0%)\n","Rosacea: 34개 (9.9%)\n","Seborrheic: 21개 (6.1%)\n","Seborrheic dermatitis: 15개 (4.3%)\n","Tinea: 14개 (4.1%)\n","Urticaria: 14개 (4.1%)\n","Vitiligo: 28개 (8.1%)\n","Wart: 27개 (7.8%)\n"]}]},{"cell_type":"code","source":["import json\n","from collections import Counter\n","\n","def analyze_sources_in_jsonl(file_path):\n","    \"\"\"\n","    JSONL 파일을 읽어서 source의 종류와 각 source별 개수를 분석하는 함수\n","    \"\"\"\n","    sources = []\n","    total_docs = 0\n","    error_count = 0\n","    no_source_count = 0\n","\n","    print(f\"분석 중: {file_path}\\n\")\n","\n","    # JSONL 파일 읽기\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        for line_num, line in enumerate(f):\n","            if not line.strip():\n","                continue\n","\n","            try:\n","                doc = json.loads(line)\n","                total_docs += 1\n","\n","                # source 키가 있는지 확인\n","                if 'source' in doc:\n","                    sources.append(doc['source'])\n","                else:\n","                    no_source_count += 1\n","\n","            except json.JSONDecodeError as e:\n","                error_count += 1\n","                print(f\"줄 {line_num + 1} 파싱 에러: {e}\")\n","\n","    # source별 개수 카운트\n","    source_counts = Counter(sources)\n","\n","    # 결과 출력\n","    print(\"=== Source 분석 결과 ===\")\n","    print(f\"총 문서 수: {total_docs}\")\n","    print(f\"source가 있는 문서 수: {len(sources)}\")\n","    print(f\"source가 없는 문서 수: {no_source_count}\")\n","    print(f\"파싱 에러 수: {error_count}\")\n","\n","    print(f\"\\n총 {len(source_counts)}개의 고유한 source가 발견되었습니다.\")\n","\n","    # source별 개수 출력 (많은 순서대로)\n","    print(\"\\n=== Source별 문서 개수 (많은 순) ===\")\n","    for source, count in source_counts.most_common():\n","        percentage = (count / len(sources) * 100) if len(sources) > 0 else 0\n","        print(f\"{source}: {count}개 ({percentage:.1f}%)\")\n","\n","    # 알파벳 순서로도 출력\n","    print(\"\\n=== Source별 문서 개수 (알파벳 순) ===\")\n","    for source in sorted(source_counts.keys()):\n","        count = source_counts[source]\n","        percentage = (count / len(sources) * 100) if len(sources) > 0 else 0\n","        print(f\"{source}: {count}개 ({percentage:.1f}%)\")\n","\n","    return source_counts\n","\n","def analyze_source_by_label(file_path):\n","    \"\"\"\n","    Label별로 source 분포를 분석하는 함수\n","    \"\"\"\n","    label_source_data = {}\n","\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            if line.strip():\n","                try:\n","                    doc = json.loads(line)\n","                    label = doc.get('label', 'NO_LABEL')\n","                    source = doc.get('source', 'NO_SOURCE')\n","\n","                    if label not in label_source_data:\n","                        label_source_data[label] = []\n","                    label_source_data[label].append(source)\n","                except:\n","                    pass\n","\n","    print(\"\\n=== Label별 Source 분포 ===\")\n","    for label in sorted(label_source_data.keys()):\n","        sources = label_source_data[label]\n","        source_counts = Counter(sources)\n","        print(f\"\\n{label} (총 {len(sources)}개 문서):\")\n","        for source, count in source_counts.most_common():\n","            percentage = (count / len(sources) * 100)\n","            print(f\"  {source}: {count}개 ({percentage:.1f}%)\")\n","\n","def save_source_analysis(file_path, output_path):\n","    \"\"\"\n","    Source 분석 결과를 텍스트 파일로 저장하는 함수\n","    \"\"\"\n","    source_counts = analyze_sources_in_jsonl(file_path)\n","\n","    with open(output_path, 'w', encoding='utf-8') as f:\n","        f.write(f\"Source 분석 결과 - {file_path}\\n\")\n","        f.write(\"=\" * 50 + \"\\n\\n\")\n","\n","        f.write(f\"총 고유 source 수: {len(source_counts)}\\n\")\n","        f.write(f\"총 문서 수: {sum(source_counts.values())}\\n\\n\")\n","\n","        f.write(\"Source별 개수 (많은 순):\\n\")\n","        f.write(\"-\" * 30 + \"\\n\")\n","        for source, count in source_counts.most_common():\n","            percentage = (count / sum(source_counts.values()) * 100)\n","            f.write(f\"{source}: {count}개 ({percentage:.1f}%)\\n\")\n","\n","        f.write(\"\\n\\nSource별 개수 (알파벳 순):\\n\")\n","        f.write(\"-\" * 30 + \"\\n\")\n","        for source in sorted(source_counts.keys()):\n","            count = source_counts[source]\n","            percentage = (count / sum(source_counts.values()) * 100)\n","            f.write(f\"{source}: {count}개 ({percentage:.1f}%)\\n\")\n","\n","    print(f\"\\n분석 결과가 '{output_path}'에 저장되었습니다.\")\n","\n","# 사용 예시\n","if __name__ == \"__main__\":\n","    # 분석할 JSONL 파일 경로\n","    jsonl_file = \"/content/updated_sources_final.jsonl\"  # 실제 파일명으로 변경\n","\n","    # 기본 source 분석\n","    source_stats = analyze_sources_in_jsonl(jsonl_file)\n","\n","    # Label별 source 분포 분석\n","    analyze_source_by_label(jsonl_file)\n","\n","    # 분석 결과를 파일로 저장하고 싶다면\n","    # save_source_analysis(jsonl_file, \"source_analysis.txt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BRhcZezwsOFO","executionInfo":{"status":"ok","timestamp":1763953685886,"user_tz":-540,"elapsed":22,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"b205758d-d6b8-49a3-92fd-3c8ed1e55a9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["분석 중: /content/updated_sources_final.jsonl\n","\n","=== Source 분석 결과 ===\n","총 문서 수: 345\n","source가 있는 문서 수: 345\n","source가 없는 문서 수: 0\n","파싱 에러 수: 0\n","\n","총 31개의 고유한 source가 발견되었습니다.\n","\n","=== Source별 문서 개수 (많은 순) ===\n","아산병원: 95개 (27.5%)\n","MSD Manual: 81개 (23.5%)\n","Wikipedia: 49개 (14.2%)\n","서울대학교병원: 18개 (5.2%)\n","대한피부과학회: 11개 (3.2%)\n","삼성서울병원: 8개 (2.3%)\n","연세대 세브란스병원: 8개 (2.3%)\n","한양대학교병원: 8개 (2.3%)\n","강남세브란스병원: 8개 (2.3%)\n","고려대학교병원: 8개 (2.3%)\n","국민건강보험공단: 8개 (2.3%)\n","경희대학교병원: 6개 (1.7%)\n","중앙대학교병원: 6개 (1.7%)\n","가천대길병원: 6개 (1.7%)\n","인하대학교병원: 5개 (1.4%)\n","Synthetic_Expert_Knowledge: 3개 (0.9%)\n","질병관리청: 2개 (0.6%)\n","가톨릭대학교 서울성모병원: 2개 (0.6%)\n","식품의약품안전처: 1개 (0.3%)\n","건국대학교병원: 1개 (0.3%)\n","한국보건의료연구원: 1개 (0.3%)\n","대한의학회: 1개 (0.3%)\n","청소년 건강행태온라인조사: 1개 (0.3%)\n","한국소비자원: 1개 (0.3%)\n","대한가정의학회: 1개 (0.3%)\n","대한소아과학회: 1개 (0.3%)\n","보건복지부: 1개 (0.3%)\n","울산대학교병원: 1개 (0.3%)\n","국립중앙의료원: 1개 (0.3%)\n","차의과학대학교 분당차병원: 1개 (0.3%)\n","대한건선학회: 1개 (0.3%)\n","\n","=== Source별 문서 개수 (알파벳 순) ===\n","MSD Manual: 81개 (23.5%)\n","Synthetic_Expert_Knowledge: 3개 (0.9%)\n","Wikipedia: 49개 (14.2%)\n","가천대길병원: 6개 (1.7%)\n","가톨릭대학교 서울성모병원: 2개 (0.6%)\n","강남세브란스병원: 8개 (2.3%)\n","건국대학교병원: 1개 (0.3%)\n","경희대학교병원: 6개 (1.7%)\n","고려대학교병원: 8개 (2.3%)\n","국립중앙의료원: 1개 (0.3%)\n","국민건강보험공단: 8개 (2.3%)\n","대한가정의학회: 1개 (0.3%)\n","대한건선학회: 1개 (0.3%)\n","대한소아과학회: 1개 (0.3%)\n","대한의학회: 1개 (0.3%)\n","대한피부과학회: 11개 (3.2%)\n","보건복지부: 1개 (0.3%)\n","삼성서울병원: 8개 (2.3%)\n","서울대학교병원: 18개 (5.2%)\n","식품의약품안전처: 1개 (0.3%)\n","아산병원: 95개 (27.5%)\n","연세대 세브란스병원: 8개 (2.3%)\n","울산대학교병원: 1개 (0.3%)\n","인하대학교병원: 5개 (1.4%)\n","중앙대학교병원: 6개 (1.7%)\n","질병관리청: 2개 (0.6%)\n","차의과학대학교 분당차병원: 1개 (0.3%)\n","청소년 건강행태온라인조사: 1개 (0.3%)\n","한국보건의료연구원: 1개 (0.3%)\n","한국소비자원: 1개 (0.3%)\n","한양대학교병원: 8개 (2.3%)\n","\n","=== Label별 Source 분포 ===\n","\n","Acne (총 67개 문서):\n","  MSD Manual: 30개 (44.8%)\n","  아산병원: 8개 (11.9%)\n","  Wikipedia: 4개 (6.0%)\n","  대한피부과학회: 3개 (4.5%)\n","  서울대학교병원: 2개 (3.0%)\n","  삼성서울병원: 1개 (1.5%)\n","  연세대 세브란스병원: 1개 (1.5%)\n","  식품의약품안전처: 1개 (1.5%)\n","  건국대학교병원: 1개 (1.5%)\n","  한양대학교병원: 1개 (1.5%)\n","  강남세브란스병원: 1개 (1.5%)\n","  고려대학교병원: 1개 (1.5%)\n","  국민건강보험공단: 1개 (1.5%)\n","  질병관리청: 1개 (1.5%)\n","  한국보건의료연구원: 1개 (1.5%)\n","  대한의학회: 1개 (1.5%)\n","  청소년 건강행태온라인조사: 1개 (1.5%)\n","  한국소비자원: 1개 (1.5%)\n","  대한가정의학회: 1개 (1.5%)\n","  대한소아과학회: 1개 (1.5%)\n","  보건복지부: 1개 (1.5%)\n","  경희대학교병원: 1개 (1.5%)\n","  울산대학교병원: 1개 (1.5%)\n","  가톨릭대학교 서울성모병원: 1개 (1.5%)\n","  중앙대학교병원: 1개 (1.5%)\n","\n","Atopic Dermatitis (총 51개 문서):\n","  MSD Manual: 20개 (39.2%)\n","  아산병원: 13개 (25.5%)\n","  Wikipedia: 5개 (9.8%)\n","  대한피부과학회: 2개 (3.9%)\n","  서울대학교병원: 2개 (3.9%)\n","  삼성서울병원: 1개 (2.0%)\n","  연세대 세브란스병원: 1개 (2.0%)\n","  한양대학교병원: 1개 (2.0%)\n","  국민건강보험공단: 1개 (2.0%)\n","  강남세브란스병원: 1개 (2.0%)\n","  고려대학교병원: 1개 (2.0%)\n","  국립중앙의료원: 1개 (2.0%)\n","  가천대길병원: 1개 (2.0%)\n","  질병관리청: 1개 (2.0%)\n","\n","Eczema (총 11개 문서):\n","  아산병원: 6개 (54.5%)\n","  Wikipedia: 5개 (45.5%)\n","\n","Folliculitis (총 15개 문서):\n","  서울대학교병원: 2개 (13.3%)\n","  아산병원: 2개 (13.3%)\n","  대한피부과학회: 1개 (6.7%)\n","  삼성서울병원: 1개 (6.7%)\n","  연세대 세브란스병원: 1개 (6.7%)\n","  한양대학교병원: 1개 (6.7%)\n","  강남세브란스병원: 1개 (6.7%)\n","  국민건강보험공단: 1개 (6.7%)\n","  고려대학교병원: 1개 (6.7%)\n","  중앙대학교병원: 1개 (6.7%)\n","  경희대학교병원: 1개 (6.7%)\n","  인하대학교병원: 1개 (6.7%)\n","  가천대길병원: 1개 (6.7%)\n","\n","Normal (총 3개 문서):\n","  Synthetic_Expert_Knowledge: 3개 (100.0%)\n","\n","Psoriasis (총 45개 문서):\n","  MSD Manual: 15개 (33.3%)\n","  아산병원: 12개 (26.7%)\n","  Wikipedia: 5개 (11.1%)\n","  서울대학교병원: 3개 (6.7%)\n","  대한피부과학회: 1개 (2.2%)\n","  삼성서울병원: 1개 (2.2%)\n","  연세대 세브란스병원: 1개 (2.2%)\n","  한양대학교병원: 1개 (2.2%)\n","  강남세브란스병원: 1개 (2.2%)\n","  국민건강보험공단: 1개 (2.2%)\n","  고려대학교병원: 1개 (2.2%)\n","  가톨릭대학교 서울성모병원: 1개 (2.2%)\n","  차의과학대학교 분당차병원: 1개 (2.2%)\n","  대한건선학회: 1개 (2.2%)\n","\n","Rosacea (총 34개 문서):\n","  아산병원: 9개 (26.5%)\n","  MSD Manual: 7개 (20.6%)\n","  Wikipedia: 5개 (14.7%)\n","  서울대학교병원: 2개 (5.9%)\n","  대한피부과학회: 1개 (2.9%)\n","  삼성서울병원: 1개 (2.9%)\n","  연세대 세브란스병원: 1개 (2.9%)\n","  한양대학교병원: 1개 (2.9%)\n","  강남세브란스병원: 1개 (2.9%)\n","  국민건강보험공단: 1개 (2.9%)\n","  고려대학교병원: 1개 (2.9%)\n","  중앙대학교병원: 1개 (2.9%)\n","  경희대학교병원: 1개 (2.9%)\n","  인하대학교병원: 1개 (2.9%)\n","  가천대길병원: 1개 (2.9%)\n","\n","Seborrheic Dermatitis (총 36개 문서):\n","  아산병원: 12개 (33.3%)\n","  MSD Manual: 6개 (16.7%)\n","  Wikipedia: 5개 (13.9%)\n","  서울대학교병원: 2개 (5.6%)\n","  대한피부과학회: 1개 (2.8%)\n","  삼성서울병원: 1개 (2.8%)\n","  연세대 세브란스병원: 1개 (2.8%)\n","  한양대학교병원: 1개 (2.8%)\n","  강남세브란스병원: 1개 (2.8%)\n","  국민건강보험공단: 1개 (2.8%)\n","  고려대학교병원: 1개 (2.8%)\n","  중앙대학교병원: 1개 (2.8%)\n","  인하대학교병원: 1개 (2.8%)\n","  경희대학교병원: 1개 (2.8%)\n","  가천대길병원: 1개 (2.8%)\n","\n","Tinea (총 14개 문서):\n","  아산병원: 6개 (42.9%)\n","  Wikipedia: 5개 (35.7%)\n","  MSD Manual: 3개 (21.4%)\n","\n","Urticaria (총 14개 문서):\n","  아산병원: 9개 (64.3%)\n","  Wikipedia: 5개 (35.7%)\n","\n","Vitiligo (총 28개 문서):\n","  아산병원: 10개 (35.7%)\n","  Wikipedia: 5개 (17.9%)\n","  서울대학교병원: 2개 (7.1%)\n","  대한피부과학회: 1개 (3.6%)\n","  삼성서울병원: 1개 (3.6%)\n","  연세대 세브란스병원: 1개 (3.6%)\n","  한양대학교병원: 1개 (3.6%)\n","  강남세브란스병원: 1개 (3.6%)\n","  국민건강보험공단: 1개 (3.6%)\n","  고려대학교병원: 1개 (3.6%)\n","  중앙대학교병원: 1개 (3.6%)\n","  경희대학교병원: 1개 (3.6%)\n","  인하대학교병원: 1개 (3.6%)\n","  가천대길병원: 1개 (3.6%)\n","\n","Wart (총 27개 문서):\n","  아산병원: 8개 (29.6%)\n","  Wikipedia: 5개 (18.5%)\n","  서울대학교병원: 3개 (11.1%)\n","  대한피부과학회: 1개 (3.7%)\n","  삼성서울병원: 1개 (3.7%)\n","  연세대 세브란스병원: 1개 (3.7%)\n","  한양대학교병원: 1개 (3.7%)\n","  강남세브란스병원: 1개 (3.7%)\n","  국민건강보험공단: 1개 (3.7%)\n","  고려대학교병원: 1개 (3.7%)\n","  중앙대학교병원: 1개 (3.7%)\n","  경희대학교병원: 1개 (3.7%)\n","  인하대학교병원: 1개 (3.7%)\n","  가천대길병원: 1개 (3.7%)\n"]}]},{"cell_type":"code","source":["import json\n","\n","def update_sources_in_jsonl(input_file, output_file):\n","    \"\"\"\n","    JSONL 파일의 source 값을 업데이트하는 함수\n","    \"\"\"\n","    # 변경할 source 매핑\n","    source_mapping = {\n","        \"서울아산병원\": \"아산병원\",\n","        \"Asan\": \"아산병원\",\n","        \"대한피부과학회 아토피피부염 가이드라인\": \"대한피부과학회\",\n","        \"대한피부과학회 여드름 가이드라인\": \"대한피부과학회\",\n","        \"분당서울대학교병원\": \"서울대학교병원\",\n","        \"분당서울대병원\": \"서울대학교병원\",\n","        \"서울대학교 어린이병원\": \"서울대학교병원\",\n","        \"서울대학교병원 의학정보\": \"서울대학교병원\",\n","        \"연세대학교 세브란스병원\": \"연세대 세브란스병원\"\n","    }\n","\n","    updated_count = 0\n","    total_count = 0\n","    source_changes = {}\n","\n","    print(f\"파일 처리 중: {input_file}\")\n","\n","    # 읽고 쓰기\n","    with open(input_file, 'r', encoding='utf-8') as f_in, \\\n","         open(output_file, 'w', encoding='utf-8') as f_out:\n","\n","        for line_num, line in enumerate(f_in):\n","            if not line.strip():\n","                continue\n","\n","            try:\n","                doc = json.loads(line)\n","                total_count += 1\n","\n","                # source가 있는 경우\n","                if 'source' in doc:\n","                    old_source = doc['source']\n","\n","                    # 변경이 필요한 경우\n","                    if old_source in source_mapping:\n","                        new_source = source_mapping[old_source]\n","                        doc['source'] = new_source\n","                        updated_count += 1\n","\n","                        # 변경 내역 기록\n","                        if old_source not in source_changes:\n","                            source_changes[old_source] = 0\n","                        source_changes[old_source] += 1\n","\n","                # 수정된(또는 원본) 문서를 출력 파일에 쓰기\n","                json.dump(doc, f_out, ensure_ascii=False)\n","                f_out.write('\\n')\n","\n","            except json.JSONDecodeError as e:\n","                print(f\"줄 {line_num + 1} 파싱 에러: {e}\")\n","                f_out.write(line)\n","\n","    # 결과 출력\n","    print(f\"\\n=== Source 업데이트 결과 ===\")\n","    print(f\"총 처리된 문서 수: {total_count}\")\n","    print(f\"업데이트된 문서 수: {updated_count}\")\n","\n","    if source_changes:\n","        print(f\"\\n변경 내역:\")\n","        for old_source, count in sorted(source_changes.items()):\n","            new_source = source_mapping[old_source]\n","            print(f\"  '{old_source}' → '{new_source}': {count}개\")\n","    else:\n","        print(\"\\n변경된 source가 없습니다.\")\n","\n","    print(f\"\\n결과가 '{output_file}'에 저장되었습니다.\")\n","\n","    return updated_count"],"metadata":{"id":"HDPxl9Zhz5FH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","\n","def view_documents_by_source(file_path, target_source, max_display=None):\n","    \"\"\"\n","    특정 source에 해당하는 모든 문서를 보는 함수\n","\n","    Args:\n","        file_path: JSONL 파일 경로\n","        target_source: 찾고자 하는 source 값\n","        max_display: 출력할 최대 문서 수 (None이면 모두 출력)\n","    \"\"\"\n","    matching_docs = []\n","\n","    print(f\"\\n=== Source '{target_source}'에 해당하는 문서 검색 ===\\n\")\n","\n","    # JSONL 파일 읽기\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        for line_num, line in enumerate(f):\n","            if not line.strip():\n","                continue\n","\n","            try:\n","                doc = json.loads(line)\n","                if doc.get('source') == target_source:\n","                    matching_docs.append({\n","                        'line_num': line_num + 1,\n","                        'doc': doc\n","                    })\n","            except json.JSONDecodeError:\n","                pass\n","\n","    # 결과 출력\n","    print(f\"총 {len(matching_docs)}개의 문서를 찾았습니다.\")\n","\n","    if matching_docs:\n","        # 출력할 문서 수 결정\n","        display_count = len(matching_docs) if max_display is None else min(max_display, len(matching_docs))\n","\n","        print(f\"\\n{'모든' if max_display is None else f'처음 {display_count}개'} 문서 출력:\\n\")\n","        print(\"=\"*80)\n","\n","        for i, item in enumerate(matching_docs[:display_count]):\n","            doc = item['doc']\n","            print(f\"\\n[문서 {i+1}] (줄 번호: {item['line_num']})\")\n","            print(f\"Source: {doc.get('source', 'N/A')}\")\n","            print(f\"Label: {doc.get('label', 'N/A')}\")\n","            print(f\"Title: {doc.get('title', doc.get('section', 'N/A'))}\")\n","            print(f\"Document Type: {doc.get('document_type', 'N/A')}\")\n","            print(f\"Text Length: {doc.get('text_length', 'N/A')}\")\n","            print(f\"Text: {doc.get('text', 'N/A')[:200]}{'...' if len(doc.get('text', '')) > 200 else ''}\")\n","            print(\"-\"*80)\n","\n","        if max_display and len(matching_docs) > max_display:\n","            print(f\"\\n... 그리고 {len(matching_docs) - max_display}개 더 있습니다.\")\n","\n","        # 통계 정보\n","        print(f\"\\n=== 통계 정보 ===\")\n","\n","        # Label별 분포\n","        labels = [item['doc'].get('label', 'Unknown') for item in matching_docs]\n","        label_counts = {}\n","        for label in labels:\n","            label_counts[label] = label_counts.get(label, 0) + 1\n","\n","        print(f\"\\nLabel별 분포:\")\n","        for label, count in sorted(label_counts.items(), key=lambda x: x[1], reverse=True):\n","            print(f\"  {label}: {count}개 ({count/len(matching_docs)*100:.1f}%)\")\n","\n","        # Document Type별 분포\n","        doc_types = [item['doc'].get('document_type', 'Unknown') for item in matching_docs]\n","        doc_type_counts = {}\n","        for doc_type in doc_types:\n","            doc_type_counts[doc_type] = doc_type_counts.get(doc_type, 0) + 1\n","\n","        print(f\"\\nDocument Type별 분포:\")\n","        for doc_type, count in sorted(doc_type_counts.items(), key=lambda x: x[1], reverse=True):\n","            print(f\"  {doc_type}: {count}개 ({count/len(matching_docs)*100:.1f}%)\")\n","\n","        # 평균 텍스트 길이\n","        text_lengths = [item['doc'].get('text_length', 0) for item in matching_docs]\n","        if text_lengths:\n","            avg_length = sum(text_lengths) / len(text_lengths)\n","            print(f\"\\n평균 텍스트 길이: {avg_length:.1f} 글자\")\n","\n","    else:\n","        print(f\"\\nSource '{target_source}'에 해당하는 문서를 찾을 수 없습니다.\")\n","\n","    return matching_docs\n","\n","def save_source_documents_to_file(file_path, target_source, output_file):\n","    \"\"\"\n","    특정 source의 문서들을 별도 파일로 저장하는 함수\n","    \"\"\"\n","    print(f\"\\nSource '{target_source}'의 문서를 '{output_file}'에 저장 중...\")\n","\n","    matching_docs = []\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            if line.strip():\n","                try:\n","                    doc = json.loads(line)\n","                    if doc.get('source') == target_source:\n","                        matching_docs.append(doc)\n","                except:\n","                    pass\n","\n","    if matching_docs:\n","        with open(output_file, 'w', encoding='utf-8') as f:\n","            for doc in matching_docs:\n","                json.dump(doc, f, ensure_ascii=False)\n","                f.write('\\n')\n","\n","        print(f\"{len(matching_docs)}개의 문서를 저장했습니다.\")\n","    else:\n","        print(\"해당 source의 문서를 찾을 수 없습니다.\")\n","\n","# 사용 예시\n","if __name__ == \"__main__\":\n","    # 1. Source 업데이트 사용 예시\n","    input_file = \"updated_labels_final.jsonl\"\n","    output_file = \"updated_sources_final.jsonl\"\n","\n","    update_sources_in_jsonl(input_file, output_file)\n","\n","    # 모든 문서를 보려면 max_display=None\n","    # view_documents_by_source(output_file, \"서울대학교병원\", max_display=None)\n","\n","    # 특정 source의 문서를 별도 파일로 저장\n","    # save_source_documents_to_file(output_file, \"대한피부과학회\", \"dermatology_society_docs.jsonl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"6xrrlJU60jGx","executionInfo":{"status":"ok","timestamp":1763953510693,"user_tz":-540,"elapsed":26,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"9dfdfb7f-944d-4c0e-ca70-c88c8fb5ea65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["파일 처리 중: updated_labels_final.jsonl\n","\n","=== Source 업데이트 결과 ===\n","총 처리된 문서 수: 345\n","업데이트된 문서 수: 101\n","\n","변경 내역:\n","  'Asan' → '아산병원': 80개\n","  '대한피부과학회 아토피피부염 가이드라인' → '대한피부과학회': 1개\n","  '대한피부과학회 여드름 가이드라인' → '대한피부과학회': 1개\n","  '분당서울대병원' → '서울대학교병원': 7개\n","  '분당서울대학교병원' → '서울대학교병원': 1개\n","  '서울대학교 어린이병원' → '서울대학교병원': 2개\n","  '서울대학교병원 의학정보' → '서울대학교병원': 1개\n","  '서울아산병원' → '아산병원': 7개\n","  '연세대학교 세브란스병원' → '연세대 세브란스병원': 1개\n","\n","결과가 'updated_sources_final.jsonl'에 저장되었습니다.\n","\n","================================================================================\n","\n","\n","=== Source '아산병원'에 해당하는 문서 검색 ===\n","\n","총 95개의 문서를 찾았습니다.\n","\n","처음 5개 문서 출력:\n","\n","================================================================================\n","\n","[문서 1] (줄 번호: 85)\n","Source: 아산병원\n","Label: Acne\n","Title: 정의\n","Document Type: oracle\n","Text Length: 247\n","Text: 여드름은 털을 만드는 모낭에 붙어 있는 피지선에 발생하는 만성 염증성 질환입니다. 여드름은 보통 사춘기에 발생하지만, 어른에게도 나타날 수 있습니다. 여드름은 얼굴, 목, 등, 가슴 등과 같이 유분이 많은 피부 부위에 잘 생깁니다. 정상적인 상태에서 피지는 모낭 벽을 따라 위로 올라가서 피부를 통해 밖으로 배출됩니다. 피지가 피부 밖으로 배출되지 못하고 모...\n","--------------------------------------------------------------------------------\n","\n","[문서 2] (줄 번호: 86)\n","Source: 아산병원\n","Label: Acne\n","Title: 원인\n","Document Type: oracle\n","Text Length: 313\n","Text: 여드름은 호르몬 변화, 세균 감염, 유전성 요인 등으로 발생한다고 여겨지지만, 아직까지 정확한 원인을 모르는 상태입니다. 대체로 사춘기에 나타나는 여드름은 안드로겐이라는 남성호르몬에 자극받아 피지를 과다하게 내보내서 발생합니다. 하지만 성인 여드름은 여성에게 많이 나타나며, 특히 생리 전에 주기적으로 악화됩니다. 이 경우 프로게스테론이라는 황체호르몬, 기름...\n","--------------------------------------------------------------------------------\n","\n","[문서 3] (줄 번호: 87)\n","Source: 아산병원\n","Label: Acne\n","Title: 증상\n","Document Type: oracle\n","Text Length: 326\n","Text: 여드름의 증상으로 면포, 구진, 농포 등이 나타납니다. 심한 경우에는 결절이나 낭종이 생깁니다. 면포란 피지가 축적되어 모낭이 팽창한 것입니다. 면포에는 모낭 입구가 열려 있습니다. 면포에는 개방 면포와 폐쇄 면포라는 두 가지 종류가 있습니다. 흔히 블랙헤드라고도 하는 개방 면포는 그간 축적된 피지의 색이 검게 보이는 것입니다. 폐쇄 면포는 표면이 닫혀 있...\n","--------------------------------------------------------------------------------\n","\n","[문서 4] (줄 번호: 88)\n","Source: 아산병원\n","Label: Acne\n","Title: 진단\n","Document Type: oracle\n","Text Length: 161\n","Text: 여드름은 보통 간단한 검진만으로 진단합니다. 얼굴, 가슴, 등, 팔, 어깨 등 증상이 발생한 부위를 관찰합니다. 환자의 병이나 건강 상태를 질문하여 여드름 유발과 관련된 요소들이 있는지 찾아냅니다. 다만, 여드름이 심한 경우 원인 질환을 감별하기 위해 여러 가지 호르몬 검사를 시행합니다.\n","--------------------------------------------------------------------------------\n","\n","[문서 5] (줄 번호: 89)\n","Source: 아산병원\n","Label: Acne\n","Title: 치료\n","Document Type: oracle\n","Text Length: 276\n","Text: 여드름 치료 방법은 크게 바르는 약, 먹는 약, 외과적 치료로 나눌 수 있습니다. 여드름을 치료하는 원리는 막힌 모낭을 제거하여 피지가 잘 배출되도록 하거나, 세균의 성장과 염증, 피지 분비를 억제하는 것입니다. 여드름의 심한 정도와 형태에 따라서 먹는 약과 바르는 약을 단독으로 혹은 복합하여 선택합니다. 이러한 약에는 부작용이 있을 수 있으므로 의사의 처...\n","--------------------------------------------------------------------------------\n","\n","... 그리고 90개 더 있습니다.\n","\n","=== 통계 정보 ===\n","\n","Label별 분포:\n","  Atopic Dermatitis: 13개 (13.7%)\n","  Psoriasis: 12개 (12.6%)\n","  Seborrheic Dermatitis: 12개 (12.6%)\n","  Vitiligo: 10개 (10.5%)\n","  Rosacea: 9개 (9.5%)\n","  Urticaria: 9개 (9.5%)\n","  Acne: 8개 (8.4%)\n","  Wart: 8개 (8.4%)\n","  Eczema: 6개 (6.3%)\n","  Tinea: 6개 (6.3%)\n","  Folliculitis: 2개 (2.1%)\n","\n","Document Type별 분포:\n","  oracle: 54개 (56.8%)\n","  distractor: 41개 (43.2%)\n","\n","평균 텍스트 길이: 233.9 글자\n"]}]},{"cell_type":"code","source":["import json\n","\n","def update_normal_document_type(input_file, output_file):\n","    \"\"\"\n","    label이 'Normal'인 문서의 document_type을 'oracle'로 변경하는 함수\n","    \"\"\"\n","    updated_count = 0\n","    total_count = 0\n","    normal_count = 0\n","    already_oracle = 0\n","\n","    print(f\"파일 처리 중: {input_file}\")\n","\n","    # 읽고 쓰기\n","    with open(input_file, 'r', encoding='utf-8') as f_in, \\\n","         open(output_file, 'w', encoding='utf-8') as f_out:\n","\n","        for line_num, line in enumerate(f_in):\n","            if not line.strip():\n","                continue\n","\n","            try:\n","                doc = json.loads(line)\n","                total_count += 1\n","\n","                # label이 'Normal'인 경우\n","                if doc.get('label') == 'Normal':\n","                    normal_count += 1\n","\n","                    # document_type이 이미 oracle인지 확인\n","                    if doc.get('document_type') == 'oracle':\n","                        already_oracle += 1\n","                    else:\n","                        # oracle로 변경\n","                        old_type = doc.get('document_type', 'None')\n","                        doc['document_type'] = 'oracle'\n","                        updated_count += 1\n","\n","                        if line_num < 3:  # 처음 몇 개 샘플 출력\n","                            print(f\"\\n변경 예시 {line_num + 1}:\")\n","                            print(f\"  Label: {doc.get('label')}\")\n","                            print(f\"  Document type: '{old_type}' → 'oracle'\")\n","\n","                # 수정된(또는 원본) 문서를 출력 파일에 쓰기\n","                json.dump(doc, f_out, ensure_ascii=False)\n","                f_out.write('\\n')\n","\n","            except json.JSONDecodeError as e:\n","                print(f\"줄 {line_num + 1} 파싱 에러: {e}\")\n","                f_out.write(line)\n","\n","    # 결과 출력\n","    print(f\"\\n=== Document Type 업데이트 결과 ===\")\n","    print(f\"총 처리된 문서 수: {total_count}\")\n","    print(f\"Label이 'Normal'인 문서 수: {normal_count}\")\n","    print(f\"  - 이미 oracle인 문서: {already_oracle}\")\n","    print(f\"  - oracle로 변경된 문서: {updated_count}\")\n","\n","    print(f\"\\n결과가 '{output_file}'에 저장되었습니다.\")\n","\n","    return updated_count\n","\n","def verify_normal_documents(file_path):\n","    \"\"\"\n","    업데이트 후 Normal label 문서들의 document_type 확인\n","    \"\"\"\n","    normal_docs = []\n","    doc_type_counts = {}\n","\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            if line.strip():\n","                try:\n","                    doc = json.loads(line)\n","                    if doc.get('label') == 'Normal':\n","                        normal_docs.append(doc)\n","                        doc_type = doc.get('document_type', 'None')\n","                        doc_type_counts[doc_type] = doc_type_counts.get(doc_type, 0) + 1\n","                except:\n","                    pass\n","\n","    print(f\"\\n=== Normal Label 문서 검증 ===\")\n","    print(f\"Total Normal 문서: {len(normal_docs)}개\")\n","    print(\"\\nDocument Type 분포:\")\n","    for doc_type, count in sorted(doc_type_counts.items()):\n","        print(f\"  {doc_type}: {count}개 ({count/len(normal_docs)*100:.1f}%)\")\n","\n","    # oracle이 아닌 문서가 있는지 확인\n","    non_oracle = sum(count for doc_type, count in doc_type_counts.items() if doc_type != 'oracle')\n","    if non_oracle > 0:\n","        print(f\"\\n⚠️ 경고: {non_oracle}개의 Normal 문서가 아직 oracle이 아닙니다!\")\n","    else:\n","        print(\"\\n✅ 모든 Normal 문서가 oracle로 설정되었습니다.\")\n","\n","    # 샘플 출력\n","    print(\"\\n처음 3개 Normal 문서 샘플:\")\n","    for i, doc in enumerate(normal_docs[:3]):\n","        print(f\"\\n문서 {i+1}:\")\n","        print(f\"  Label: {doc.get('label')}\")\n","        print(f\"  Document Type: {doc.get('document_type')}\")\n","        print(f\"  Source: {doc.get('source')}\")\n","        print(f\"  Text: {doc.get('text', '')[:100]}...\")\n","\n","# 사용 예시\n","if __name__ == \"__main__\":\n","    # 입력/출력 파일 지정\n","    input_file = \"updated_sources_final.jsonl\"  # 실제 파일명으로 변경\n","    output_file = \"updated_normal_oracle.jsonl\"\n","\n","    # Normal label의 document_type을 oracle로 변경\n","    update_normal_document_type(input_file, output_file)\n","\n","    # 변경 결과 확인\n","    print(\"\\n\" + \"=\"*50)\n","    verify_normal_documents(output_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"sHayabTX3uiX","executionInfo":{"status":"ok","timestamp":1763954328395,"user_tz":-540,"elapsed":23,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"49497115-0cc1-4fbd-faab-86f125ab02eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["파일 처리 중: updated_sources_final.jsonl\n","\n","=== Document Type 업데이트 결과 ===\n","총 처리된 문서 수: 345\n","Label이 'Normal'인 문서 수: 3\n","  - 이미 oracle인 문서: 0\n","  - oracle로 변경된 문서: 3\n","\n","결과가 'updated_normal_oracle.jsonl'에 저장되었습니다.\n","\n","==================================================\n","\n","=== Normal Label 문서 검증 ===\n","Total Normal 문서: 3개\n","\n","Document Type 분포:\n","  oracle: 3개 (100.0%)\n","\n","✅ 모든 Normal 문서가 oracle로 설정되었습니다.\n","\n","처음 3개 Normal 문서 샘플:\n","\n","문서 1:\n","  Label: Normal\n","  Document Type: oracle\n","  Source: Synthetic_Expert_Knowledge\n","  Text: 정상 피부(Eudermic skin)는 유수분 밸런스가 이상적이며, 각질이나 붉은 반점, 가려움증이 없는 건강한 상태를 말합니다....\n","\n","문서 2:\n","  Label: Normal\n","  Document Type: oracle\n","  Source: Synthetic_Expert_Knowledge\n","  Text: 정상 피부의 모공은 작고 눈에 잘 띄지 않으며, 피지 분비가 적절하여 번들거리지 않습니다....\n","\n","문서 3:\n","  Label: Normal\n","  Document Type: oracle\n","  Source: Synthetic_Expert_Knowledge\n","  Text: 일시적 붉은기만 있으면 병적 상태가 아닌 정상 반응일 가능성이 높습니다....\n"]}]},{"cell_type":"code","source":["# 예시: '아산병원' source의 문서 보기 (처음 5개만)\n","view_documents_by_source(output_file, \"청소년 건강행태온라인조사\", max_display=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"1scmkZ2z1MVu","executionInfo":{"status":"ok","timestamp":1763954653632,"user_tz":-540,"elapsed":47,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"53081210-a084-479b-c123-df6ed4bcba7b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Source '청소년 건강행태온라인조사'에 해당하는 문서 검색 ===\n","\n","총 1개의 문서를 찾았습니다.\n","\n","처음 1개 문서 출력:\n","\n","================================================================================\n","\n","[문서 1] (줄 번호: 230)\n","Source: 청소년 건강행태온라인조사\n","Label: Acne\n","Title: 청소년 여드름의 심리적 영향\n","Document Type: oracle\n","Text Length: 186\n","Text: 청소년기 여드름은 신체적 문제뿐만 아니라 심리적 영향도 큽니다. 외모에 대한 스트레스, 자신감 저하, 사회적 위축 등이 나타날 수 있습니다. 심한 경우 우울증이나 불안증으로 이어질 수 있어 적극적인 치료와 심리적 지지가 필요합니다. 가족과 친구들의 이해와 격려가 중요하며, 필요시 정신건강 전문가의 도움을 받는 것도 고려해야 합니다.\n","--------------------------------------------------------------------------------\n","\n","=== 통계 정보 ===\n","\n","Label별 분포:\n","  Acne: 1개 (100.0%)\n","\n","Document Type별 분포:\n","  oracle: 1개 (100.0%)\n","\n","평균 텍스트 길이: 186.0 글자\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'line_num': 230,\n","  'doc': {'source': '청소년 건강행태온라인조사',\n","   'label': 'Acne',\n","   'title': '청소년 여드름의 심리적 영향',\n","   'text': '청소년기 여드름은 신체적 문제뿐만 아니라 심리적 영향도 큽니다. 외모에 대한 스트레스, 자신감 저하, 사회적 위축 등이 나타날 수 있습니다. 심한 경우 우울증이나 불안증으로 이어질 수 있어 적극적인 치료와 심리적 지지가 필요합니다. 가족과 친구들의 이해와 격려가 중요하며, 필요시 정신건강 전문가의 도움을 받는 것도 고려해야 합니다.',\n","   'text_length': 186,\n","   'document_type': 'oracle'}}]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["import json\n","\n","def extract_specific_labels(input_file, output_file, target_labels):\n","    \"\"\"\n","    JSONL 파일에서 특정 label의 문서만 추출하여 텍스트 파일로 저장\n","\n","    Args:\n","        input_file: 입력 JSONL 파일 경로\n","        output_file: 출력 텍스트 파일 경로\n","        target_labels: 추출할 label 리스트\n","    \"\"\"\n","    extracted_docs = []\n","\n","    # JSONL 파일 읽기\n","    with open(input_file, 'r', encoding='utf-8') as f:\n","        for line_num, line in enumerate(f):\n","            if not line.strip():\n","                continue\n","\n","            try:\n","                doc = json.loads(line)\n","                # 특정 label인 경우만 추출\n","                if doc.get('label') in target_labels:\n","                    extracted_docs.append(doc)\n","            except json.JSONDecodeError as e:\n","                print(f\"줄 {line_num + 1} 파싱 에러: {e}\")\n","\n","    # 텍스트 파일로 저장\n","    with open(output_file, 'w', encoding='utf-8') as f:\n","        # Label별로 구분하여 저장\n","        for label in target_labels:\n","            label_docs = [doc for doc in extracted_docs if doc.get('label') == label]\n","\n","            if label_docs:\n","                f.write(f\"{'='*80}\\n\")\n","                f.write(f\"LABEL: {label} (총 {len(label_docs)}개 문서)\\n\")\n","                f.write(f\"{'='*80}\\n\\n\")\n","\n","                for i, doc in enumerate(label_docs, 1):\n","                    f.write(f\"[문서 {i}]\\n\")\n","                    f.write(f\"Label: {doc.get('label', 'N/A')}\\n\")\n","                    f.write(f\"Source: {doc.get('source', 'N/A')}\\n\")\n","                    f.write(f\"Title: {doc.get('title', 'N/A')}\\n\")\n","                    f.write(f\"Document Type: {doc.get('document_type', 'N/A')}\\n\")\n","                    f.write(f\"Text Length: {doc.get('text_length', 'N/A')}\\n\")\n","                    f.write(f\"Text: {doc.get('text', 'N/A')}\\n\")\n","                    f.write(f\"{'-'*80}\\n\\n\")\n","\n","    print(f\"추출 완료:\")\n","    for label in target_labels:\n","        count = len([doc for doc in extracted_docs if doc.get('label') == label])\n","        print(f\"  {label}: {count}개\")\n","    print(f\"총 {len(extracted_docs)}개 문서를 '{output_file}'에 저장했습니다.\")\n","\n","    return extracted_docs\n","\n","def extract_text_only(input_file, output_file, target_labels):\n","    \"\"\"\n","    특정 label의 text 내용만 추출하여 저장 (쿼리 생성용)\n","    \"\"\"\n","    texts_by_label = {label: [] for label in target_labels}\n","\n","    with open(input_file, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            if line.strip():\n","                try:\n","                    doc = json.loads(line)\n","                    if doc.get('label') in target_labels:\n","                        texts_by_label[doc['label']].append({\n","                            'title': doc.get('title', 'No title'),\n","                            'text': doc.get('text', ''),\n","                            'source': doc.get('source', 'Unknown')\n","                        })\n","                except:\n","                    pass\n","\n","    # 텍스트만 저장\n","    with open(output_file, 'w', encoding='utf-8') as f:\n","        for label in target_labels:\n","            texts = texts_by_label[label]\n","            if texts:\n","                f.write(f\"\\n{'='*80}\\n\")\n","                f.write(f\"LABEL: {label} (총 {len(texts)}개)\\n\")\n","                f.write(f\"{'='*80}\\n\\n\")\n","\n","                for i, item in enumerate(texts, 1):\n","                    f.write(f\"[{label} - 문서 {i}] {item['title']} (출처: {item['source']})\\n\")\n","                    f.write(f\"{item['text']}\\n\")\n","                    f.write(f\"\\n{'-'*40}\\n\\n\")\n","\n","    print(f\"\\nText만 추출 완료:\")\n","    for label, texts in texts_by_label.items():\n","        print(f\"  {label}: {len(texts)}개\")\n","\n","# 사용 예시\n","if __name__ == \"__main__\":\n","    # 입력 파일과 추출할 label 설정\n","    input_jsonl = \"raft_dataset_final.jsonl\"  # 실제 파일명으로 변경\n","    output_txt = \"atopic_seborrheic_docs.txt\"\n","    output_text_only = \"atopic_seborrheic_texts.txt\"\n","\n","    target_labels = [\"Atopic Dermatitis\", \"Seborrheic Dermatitis\"]\n","\n","    # 전체 정보 추출\n","    extract_specific_labels(input_jsonl, output_txt, target_labels)\n","\n","    # 텍스트만 추출 (쿼리 생성용)\n","    extract_text_only(input_jsonl, output_text_only, target_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zv_kT4k8JgA3","executionInfo":{"status":"ok","timestamp":1764038499776,"user_tz":-540,"elapsed":45,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"d81f743c-6241-4112-a62d-2b86462c53e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["추출 완료:\n","  Atopic Dermatitis: 51개\n","  Seborrheic Dermatitis: 36개\n","총 87개 문서를 'atopic_seborrheic_docs.txt'에 저장했습니다.\n","\n","Text만 추출 완료:\n","  Atopic Dermatitis: 51개\n","  Seborrheic Dermatitis: 36개\n"]}]},{"cell_type":"markdown","source":["##**학습데이터 제작**"],"metadata":{"id":"H-4vgVvnzOox"}},{"cell_type":"code","source":["import json\n","import re\n","\n","def parse_text_file_debug(file_path):\n","    \"\"\"\n","    텍스트 파일을 파싱하여 문서와 질문들을 추출하는 함수 (디버깅 버전)\n","    \"\"\"\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        content = f.read()\n","\n","    print(f\"파일 크기: {len(content)} 문자\")\n","    print(f\"첫 500자: {content[:500]}\")\n","    print(\"-\" * 50)\n","\n","    documents = []\n","\n","    # 더 간단한 방법: 청크별로 분리\n","    # JSON과 질문이 연속으로 나타나는 패턴을 찾기\n","\n","    # 방법 1: JSON 문자열 패턴으로 찾기\n","    json_pattern = r'\\{[^}]+?\"document_type\":\\s*\"oracle\"\\s*\\}'\n","    json_matches = re.finditer(json_pattern, content, re.DOTALL)\n","\n","    json_positions = []\n","    for match in json_matches:\n","        json_str = match.group()\n","        try:\n","            doc_data = json.loads(json_str)\n","            json_positions.append((match.start(), match.end(), doc_data))\n","            print(f\"JSON 찾음: {doc_data['label']} - {doc_data['title']}\")\n","        except json.JSONDecodeError as e:\n","            print(f\"JSON 파싱 실패: {e}\")\n","\n","    print(f\"\\n찾은 JSON 문서 수: {len(json_positions)}\")\n","\n","    # 각 JSON 문서 다음에 나오는 질문들 찾기\n","    for i, (start, end, doc_data) in enumerate(json_positions):\n","        # 현재 JSON 이후부터 다음 JSON까지의 텍스트\n","        if i < len(json_positions) - 1:\n","            next_start = json_positions[i + 1][0]\n","            section = content[end:next_start]\n","        else:\n","            section = content[end:]\n","\n","        # 질문 찾기 (숫자. 로 시작하는 라인)\n","        questions = []\n","        lines = section.split('\\n')\n","\n","        for line in lines:\n","            line = line.strip()\n","            match = re.match(r'^(\\d+)\\.\\s+(.+)$', line)\n","            if match:\n","                questions.append(match.group(2))\n","\n","        if questions:\n","            print(f\"{doc_data['label']}에 대한 질문 {len(questions)}개 찾음\")\n","            documents.append({\n","                'doc_data': doc_data,\n","                'questions': questions\n","            })\n","\n","    return documents\n","\n","def parse_text_file_alternative(file_path):\n","    \"\"\"\n","    대체 파싱 방법: 청크 단위로 처리\n","    \"\"\"\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        content = f.read()\n","\n","    documents = []\n","\n","    # **청크 1**, **청크 2** 등으로 구분된 경우\n","    chunks = re.split(r'\\*\\*청크\\s+\\d+\\*\\*', content)\n","\n","    for chunk in chunks[1:]:  # 첫 번째는 빈 문자열이므로 제외\n","        if not chunk.strip():\n","            continue\n","\n","        # JSON 찾기\n","        json_match = re.search(r'\\{[^}]+\\}', chunk, re.DOTALL)\n","        if not json_match:\n","            continue\n","\n","        try:\n","            doc_data = json.loads(json_match.group())\n","        except json.JSONDecodeError:\n","            continue\n","\n","        # 질문 찾기\n","        questions = []\n","        lines = chunk.split('\\n')\n","\n","        for line in lines:\n","            line = line.strip()\n","            match = re.match(r'^(\\d+)\\.\\s+(.+)$', line)\n","            if match:\n","                questions.append(match.group(2))\n","\n","        if questions:\n","            documents.append({\n","                'doc_data': doc_data,\n","                'questions': questions\n","            })\n","\n","    return documents\n","\n","def create_raft_data_from_documents(documents):\n","    \"\"\"\n","    파싱된 문서들로부터 RAFT 데이터 생성\n","    \"\"\"\n","    all_raft_data = []\n","    doc_counter = {}\n","\n","    for doc_item in documents:\n","        doc_data = doc_item['doc_data']\n","        questions = doc_item['questions']\n","\n","        label = doc_data['label']\n","        label_short = label.lower().replace(' ', '_')\n","\n","        if label not in doc_counter:\n","            doc_counter[label] = 1\n","        else:\n","            doc_counter[label] += 1\n","\n","        doc_id = f\"{label_short}_doc_{doc_counter[label]:03d}\"\n","\n","        for idx, question in enumerate(questions, 1):\n","            question_id = f\"{label_short}_doc{doc_counter[label]:03d}_q{idx:03d}\"\n","\n","            raft_item = {\n","                \"question_id\": question_id,\n","                \"question\": question,\n","                \"golden_doc\": {\n","                    \"doc_id\": doc_id,\n","                    \"text\": doc_data['text'],\n","                    \"label\": doc_data['label'],\n","                    \"source\": doc_data['source'],\n","                    \"document_type\": doc_data['document_type'],\n","                    \"title\": doc_data.get('title', ''),\n","                    \"text_length\": doc_data.get('text_length', len(doc_data['text']))\n","                }\n","            }\n","\n","            all_raft_data.append(raft_item)\n","\n","    return all_raft_data\n","\n","def save_as_jsonl(raft_data, output_file):\n","    \"\"\"\n","    RAFT 데이터를 JSONL 형식으로 저장\n","    \"\"\"\n","    with open(output_file, 'w', encoding='utf-8') as f:\n","        for item in raft_data:\n","            json.dump(item, f, ensure_ascii=False)\n","            f.write('\\n')\n","\n","def process_text_file(input_file, output_file=\"raft_golden_samples.jsonl\"):\n","    \"\"\"\n","    텍스트 파일을 처리하여 RAFT 데이터 생성\n","    \"\"\"\n","    print(f\"텍스트 파일 처리 중: {input_file}\")\n","\n","    # 먼저 디버깅 버전으로 시도\n","    documents = parse_text_file_debug(input_file)\n","\n","    # 문서가 없으면 대체 방법 시도\n","    if not documents:\n","        print(\"\\n대체 파싱 방법 시도 중...\")\n","        documents = parse_text_file_alternative(input_file)\n","\n","    print(f\"\\n최종 파싱된 문서 수: {len(documents)}\")\n","\n","    if not documents:\n","        print(\"문서를 찾을 수 없습니다. 파일 형식을 확인해주세요.\")\n","        return []\n","\n","    # RAFT 데이터 생성\n","    raft_data = create_raft_data_from_documents(documents)\n","\n","    # JSONL로 저장\n","    save_as_jsonl(raft_data, output_file)\n","\n","    print(f\"\\n총 {len(raft_data)}개의 RAFT 데이터 생성 완료\")\n","    print(f\"출력 파일: {output_file}\")\n","\n","    return raft_data\n","\n","# 간단한 수동 파싱 함수 (파일 형식이 특수한 경우)\n","def manual_parse_example():\n","    \"\"\"\n","    수동으로 데이터를 입력하는 예시\n","    \"\"\"\n","    doc_json = {\"source\": \"MSD Manual\", \"label\": \"Acne\", \"title\": \"여드름의 원인\",\n","                \"text\": \"여드름은 모낭(모발이 자라는 피부의 구멍)의 염증을...\",\n","                \"text_length\": 670, \"document_type\": \"oracle\"}\n","\n","    questions = [\n","        \"여드름이 생기는 가장 기본적인 이유가 궁금해요. 호르몬, 피지, 세균이 서로 어떻게 작용해서 여드름이 되는 건가요?\",\n","        \"블랙헤드랑 패립종(화이트헤드)은 뭐가 다른 거예요?\",\n","        # ... 나머지 질문들\n","    ]\n","\n","    documents = [{\n","        'doc_data': doc_json,\n","        'questions': questions\n","    }]\n","\n","    return create_raft_data_from_documents(documents)\n","\n","if __name__ == \"__main__\":\n","    input_file = \"Q01.txt\"\n","    output_file = \"raft_golden_samples.jsonl\"\n","\n","    # 파일 처리 시도\n","    raft_data = process_text_file(input_file, output_file)\n","\n","    # 결과가 없으면 파일 내용 일부를 직접 확인\n","    if not raft_data:\n","        print(\"\\n파일 내용을 직접 확인해주세요.\")\n","        print(\"예상 형식:\")\n","        print(\"1. JSON 객체가 한 줄로 되어 있어야 함\")\n","        print(\"2. 질문은 '숫자. 질문내용' 형식이어야 함\")\n","        print(\"3. JSON과 질문 사이에 적절한 구분이 있어야 함\")"],"metadata":{"id":"Txe7XD6nzSt9","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1764037769737,"user_tz":-540,"elapsed":51,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"a8292c65-a86b-4cf5-ab47-d72e4f552ee9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["텍스트 파일 처리 중: Q01.txt\n","파일 크기: 81536 문자\n","첫 500자: **청크 1**\n","\n","```\n","{\"source\": \"MSD Manual\", \"label\": \"Acne\", \"title\": \"여드름의 원인\", \"text\": \"여드름은 모낭(모발이 자라는 피부의 구멍)의 염증을 일으키는 호르몬, 피지, 세균 간의 상호작용에 의해 발생합니다. 여드름은 많은 유형의 피부 이상(병변)을 특징으로 합니다. 이들은 크기와 중증도에서 다르고, 일부는 다른 성장물보다 피부 깊숙이 침범합니다. 블랙헤드(열린 면포) 패립종(닫힌 면포) 뾰루지(염증성 닫힌 면포) 융기된 딱딱한 돌기(구진) 고름이 든 표면 돌기(농포) 고름이 든 보다 깊고 단단한 돌기(결절) 고름이 된 보다 큰 주머니(낭) 때때로 고름이 든 훨씬 크고 깊은 주머니(농양) 낭과 농양은 모두 고름이 찬 주머니이지만 농양이 좀 더 크고 뿌리가 깊은 편입니다. 지방성 물질(피지)을 분비하는 피지선은 피부의 중간층인 진피층에 위치합니다. 이러한 분비선은 모낭에 붙어 있습니다. 피지는 죽은 피부 세포와 함께 피지선과 \n","--------------------------------------------------\n","JSON 찾음: Acne - 여드름의 원인\n","JSON 찾음: Acne - 여드름의 원인\n","JSON 찾음: Acne - 여드름의 원인\n","JSON 찾음: Acne - 여드름의 원인\n","JSON 찾음: Acne - 여드름의 증상\n","JSON 찾음: Acne - 여드름의 증상\n","JSON 찾음: Acne - 여드름의 증상\n","JSON 찾음: Acne - 여드름의 진단\n","JSON 찾음: Acne - 여드름의 치료\n","JSON 찾음: Acne - 여드름의 치료\n","JSON 찾음: Acne - 여드름의 치료\n","JSON 찾음: Acne - 여드름의 치료\n","JSON 찾음: Acne - 여드름의 치료\n","JSON 찾음: Acne - 여드름의 치료\n","JSON 찾음: Acne - 여드름의 치료\n","JSON 찾음: Acne - 여드름의 치료\n","JSON 찾음: Acne - 여드름의 치료\n","JSON 찾음: Acne - 여드름의 치료\n","JSON 찾음: Acne - 경증 여드름\n","JSON 찾음: Acne - 경증 여드름\n","JSON 찾음: Acne - 중등도 여드름\n","JSON 찾음: Acne - 중증 여드름\n","JSON 찾음: Acne - 중증 여드름\n","JSON 찾음: Acne - 낭성 여드름\n","JSON 찾음: Acne - 여드름 흉터\n","JSON 찾음: Acne - 여드름의 예후\n","JSON 찾음: Acne - 여드름의 치료\n","JSON 찾음: Acne - 여드름의 치료\n","JSON 찾음: Acne - 중증 여드름\n","JSON 찾음: Acne - 중증 여드름\n","JSON 찾음: Acne - 정의\n","JSON 찾음: Acne - 원인\n","JSON 찾음: Acne - 증상\n","JSON 찾음: Acne - 진단\n","JSON 찾음: Acne - 치료\n","JSON 찾음: Acne - 주의사항\n","JSON 찾음: Acne - 위키요약1\n","JSON 찾음: Acne - 위키요약2\n","JSON 찾음: Acne - 위키요약3\n","JSON 찾음: Acne - 위키요약4\n","JSON 찾음: Acne - 여드름의 기본 정의\n","JSON 찾음: Acne - 여드름 발생 4대 원인\n","JSON 찾음: Acne - 면포성 여드름의 특징\n","JSON 찾음: Acne - 염증성 여드름의 종류\n","JSON 찾음: Acne - 여드름 경증 치료법\n","JSON 찾음: Acne - 여드름 중등도 이상 치료\n","JSON 찾음: Acne - 낭포성 여드름 치료\n","JSON 찾음: Acne - 여성 호르몬성 여드름\n","JSON 찾음: Acne - 여드름 스킨케어 관리\n","JSON 찾음: Acne - 여드름과 식습관의 관계\n","JSON 찾음: Acne - 여드름 흉터의 종류와 치료\n","JSON 찾음: Acne - 임신 중 여드름 치료\n","JSON 찾음: Acne - 여드름과 스트레스의 관계\n","JSON 찾음: Acne - 여드름 치료 시 주의사항\n","JSON 찾음: Acne - 여드름 중증도 분류\n","JSON 찾음: Acne - 여드름 예방법\n","JSON 찾음: Acne - 청소년 여드름의 심리적 영향\n","JSON 찾음: Acne - 여드름과 화장품 선택\n","JSON 찾음: Acne - 여드름 치료의 단계별 접근\n","JSON 찾음: Acne - 여드름 부위별 특징\n","JSON 찾음: Acne - 여드름 치료 효과 평가\n","\n","찾은 JSON 문서 수: 61\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","Acne에 대한 질문 20개 찾음\n","\n","최종 파싱된 문서 수: 61\n","\n","총 1220개의 RAFT 데이터 생성 완료\n","출력 파일: raft_golden_samples.jsonl\n"]}]},{"cell_type":"code","source":["import json\n","import re\n","\n","def parse_alternating_format(file_path):\n","    \"\"\"\n","    JSON과 질문 리스트가 번갈아 나타나는 형식을 파싱\n","    \"\"\"\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        content = f.read()\n","\n","    documents = []\n","\n","    # JSON 객체를 찾는 정규표현식\n","    json_pattern = r'\\{[^}]+?\"document_type\":\\s*\"[^\"]+\"\\s*\\}'\n","\n","    # 모든 JSON 객체의 위치 찾기\n","    json_matches = list(re.finditer(json_pattern, content, re.DOTALL))\n","\n","    print(f\"찾은 JSON 객체 수: {len(json_matches)}\")\n","\n","    for i, match in enumerate(json_matches):\n","        json_str = match.group()\n","\n","        # JSON 파싱\n","        try:\n","            doc_data = json.loads(json_str)\n","            print(f\"\\nJSON {i+1}: {doc_data['label']} - {doc_data['title']}\")\n","        except json.JSONDecodeError as e:\n","            print(f\"JSON 파싱 에러: {e}\")\n","            continue\n","\n","        # 현재 JSON 다음부터 다음 JSON까지의 텍스트에서 질문 찾기\n","        start_pos = match.end()\n","        end_pos = json_matches[i+1].start() if i+1 < len(json_matches) else len(content)\n","\n","        question_section = content[start_pos:end_pos]\n","\n","        # 질문 찾기 (숫자. 로 시작하는 줄)\n","        questions = []\n","        lines = question_section.split('\\n')\n","\n","        for line in lines:\n","            line = line.strip()\n","            # 1. 또는 1) 형식의 질문 찾기\n","            match = re.match(r'^(\\d+)[.)\\s]+(.+)$', line)\n","            if match:\n","                question_text = match.group(2).strip()\n","                questions.append(question_text)\n","\n","        if questions:\n","            print(f\"  -> {len(questions)}개 질문 찾음\")\n","            documents.append({\n","                'doc_data': doc_data,\n","                'questions': questions\n","            })\n","\n","    return documents\n","\n","def create_raft_data_from_documents(documents):\n","    \"\"\"\n","    파싱된 문서들로부터 RAFT 데이터 생성\n","    \"\"\"\n","    all_raft_data = []\n","    doc_counter = {}\n","\n","    for doc_idx, doc_item in enumerate(documents):\n","        doc_data = doc_item['doc_data']\n","        questions = doc_item['questions']\n","\n","        label = doc_data['label']\n","        label_short = label.lower().replace(' ', '_')\n","\n","        # 라벨별 문서 카운터\n","        if label not in doc_counter:\n","            doc_counter[label] = 1\n","        else:\n","            doc_counter[label] += 1\n","\n","        # 문서 ID 생성\n","        doc_id = f\"{label_short}_doc_{doc_counter[label]:03d}\"\n","\n","        # 각 질문에 대해 RAFT 아이템 생성\n","        for q_idx, question in enumerate(questions, 1):\n","            question_id = f\"{label_short}_doc{doc_counter[label]:03d}_q{q_idx:03d}\"\n","\n","            raft_item = {\n","                \"question_id\": question_id,\n","                \"question\": question,\n","                \"golden_doc\": {\n","                    \"doc_id\": doc_id,\n","                    \"text\": doc_data['text'],\n","                    \"label\": doc_data['label'],\n","                    \"source\": doc_data['source'],\n","                    \"document_type\": doc_data['document_type'],\n","                    \"title\": doc_data.get('title', ''),\n","                    \"text_length\": doc_data.get('text_length', len(doc_data['text']))\n","                }\n","            }\n","\n","            all_raft_data.append(raft_item)\n","\n","    return all_raft_data\n","\n","def save_as_jsonl(raft_data, output_file):\n","    \"\"\"\n","    RAFT 데이터를 JSONL 형식으로 저장\n","    \"\"\"\n","    with open(output_file, 'w', encoding='utf-8') as f:\n","        for item in raft_data:\n","            json.dump(item, f, ensure_ascii=False)\n","            f.write('\\n')\n","\n","def process_alternating_format_file(input_file, output_file=\"raft_golden_samples.jsonl\"):\n","    \"\"\"\n","    번갈아 나타나는 형식의 텍스트 파일 처리\n","    \"\"\"\n","    print(f\"텍스트 파일 처리 중: {input_file}\")\n","    print(\"형식: JSON 객체와 질문 리스트가 번갈아 나타남\")\n","    print(\"-\" * 50)\n","\n","    # 문서 파싱\n","    documents = parse_alternating_format(input_file)\n","\n","    print(f\"\\n총 파싱된 문서 수: {len(documents)}\")\n","\n","    if not documents:\n","        print(\"문서를 찾을 수 없습니다.\")\n","        return []\n","\n","    # RAFT 데이터 생성\n","    raft_data = create_raft_data_from_documents(documents)\n","\n","    # JSONL로 저장\n","    save_as_jsonl(raft_data, output_file)\n","\n","    # 통계 출력\n","    print(f\"\\n=== 처리 완료 ===\")\n","    print(f\"총 {len(raft_data)}개의 RAFT 데이터 생성\")\n","    print(f\"출력 파일: {output_file}\")\n","\n","    # 라벨별 통계\n","    label_stats = {}\n","    doc_stats = {}\n","\n","    for item in raft_data:\n","        label = item['golden_doc']['label']\n","        doc_id = item['golden_doc']['doc_id']\n","\n","        if label not in label_stats:\n","            label_stats[label] = 0\n","            doc_stats[label] = set()\n","\n","        label_stats[label] += 1\n","        doc_stats[label].add(doc_id)\n","\n","    print(\"\\n라벨별 통계:\")\n","    for label in sorted(label_stats.keys()):\n","        print(f\"  {label}:\")\n","        print(f\"    - 문서 수: {len(doc_stats[label])}\")\n","        print(f\"    - 질문 수: {label_stats[label]}\")\n","        print(f\"    - 문서당 평균 질문 수: {label_stats[label] / len(doc_stats[label]):.1f}\")\n","\n","    # 샘플 출력\n","    if raft_data:\n","        print(\"\\n=== 생성된 데이터 샘플 ===\")\n","        sample = raft_data[0]\n","        print(json.dumps(sample, ensure_ascii=False, indent=2))\n","\n","    return raft_data\n","\n","# 디버깅을 위한 함수\n","def check_file_format(file_path, lines_to_check=50):\n","    \"\"\"\n","    파일 형식 확인용 함수\n","    \"\"\"\n","    print(f\"파일 형식 확인: {file_path}\")\n","    print(\"-\" * 50)\n","\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        lines = f.readlines()\n","\n","    print(f\"총 줄 수: {len(lines)}\")\n","    print(f\"처음 {lines_to_check}줄:\")\n","\n","    for i, line in enumerate(lines[:lines_to_check]):\n","        if line.strip():\n","            print(f\"{i+1}: {line[:100].strip()}{'...' if len(line) > 100 else ''}\")\n","\n","if __name__ == \"__main__\":\n","    input_file = \"Q02.txt\"  # 실제 파일명으로 변경\n","    output_file = \"raft_golden_samples02.jsonl\"\n","\n","    # 파일 형식 확인 (디버깅용)\n","    # check_file_format(input_file)\n","\n","    # 파일 처리\n","    raft_data = process_alternating_format_file(input_file, output_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"G1p7FQq63h8q","executionInfo":{"status":"ok","timestamp":1764038185548,"user_tz":-540,"elapsed":70,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"53d0da26-a614-4b59-809e-6a58d389f0ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["텍스트 파일 처리 중: Q02.txt\n","형식: JSON 객체와 질문 리스트가 번갈아 나타남\n","--------------------------------------------------\n","찾은 JSON 객체 수: 80\n","\n","JSON 1: Rosacea - 주사의 증상\n","  -> 20개 질문 찾음\n","\n","JSON 2: Rosacea - 주사의 증상\n","  -> 20개 질문 찾음\n","\n","JSON 3: Rosacea - 주사의 증상\n","  -> 20개 질문 찾음\n","\n","JSON 4: Rosacea - 주사의 진단\n","  -> 20개 질문 찾음\n","\n","JSON 5: Rosacea - 주사의 치료\n","  -> 20개 질문 찾음\n","\n","JSON 6: Rosacea - 주사의 치료\n","  -> 20개 질문 찾음\n","\n","JSON 7: Rosacea - 주사의 치료\n","  -> 20개 질문 찾음\n","\n","JSON 8: Rosacea - 정의\n","  -> 20개 질문 찾음\n","\n","JSON 9: Rosacea - 원인\n","  -> 20개 질문 찾음\n","\n","JSON 10: Rosacea - 증상\n","  -> 20개 질문 찾음\n","\n","JSON 11: Rosacea - 진단\n","  -> 20개 질문 찾음\n","\n","JSON 12: Rosacea - 치료\n","  -> 20개 질문 찾음\n","\n","JSON 13: Rosacea - 치료\n","  -> 20개 질문 찾음\n","\n","JSON 14: Rosacea - 주의사항\n","  -> 20개 질문 찾음\n","\n","JSON 15: Rosacea - 위키요약1\n","  -> 20개 질문 찾음\n","\n","JSON 16: Rosacea - 위키요약2\n","  -> 20개 질문 찾음\n","\n","JSON 17: Rosacea - 위키요약3\n","  -> 20개 질문 찾음\n","\n","JSON 18: Rosacea - 위키요약4\n","  -> 20개 질문 찾음\n","\n","JSON 19: Rosacea - 위키요약5\n","  -> 20개 질문 찾음\n","\n","JSON 20: Rosacea - 주사피부염의 정의와 특징\n","  -> 20개 질문 찾음\n","\n","JSON 21: Rosacea - 주사피부염의 발병 원인\n","  -> 20개 질문 찾음\n","\n","JSON 22: Rosacea - 주사피부염의 임상 아형\n","  -> 20개 질문 찾음\n","\n","JSON 23: Rosacea - 주사피부염의 유발 및 악화 요인\n","  -> 20개 질문 찾음\n","\n","JSON 24: Rosacea - 주사피부염의 진단\n","  -> 20개 질문 찾음\n","\n","JSON 25: Rosacea - 주사피부염의 국소 치료\n","  -> 20개 질문 찾음\n","\n","JSON 26: Rosacea - 주사피부염의 경구 치료\n","  -> 20개 질문 찾음\n","\n","JSON 27: Rosacea - 주사피부염의 레이저 치료\n","  -> 20개 질문 찾음\n","\n","JSON 28: Rosacea - 주사피부염 환자의 스킨케어\n","  -> 20개 질문 찾음\n","\n","JSON 29: Rosacea - 주사피부염과 안구 증상\n","  -> 20개 질문 찾음\n","\n","JSON 30: Rosacea - 주사피부염의 식이 관리\n","  -> 20개 질문 찾음\n","\n","JSON 31: Rosacea - 주사피부염과 정서적 영향\n","  -> 20개 질문 찾음\n","\n","JSON 32: Rosacea - 주사피부염의 장기 관리\n","  -> 20개 질문 찾음\n","\n","JSON 33: Rosacea - 주사피부염의 감별 진단\n","  -> 20개 질문 찾음\n","\n","JSON 34: Rosacea - 주사피부염의 새로운 치료법\n","  -> 20개 질문 찾음\n","\n","JSON 35: Psoriasis - 건선의 증상\n","  -> 20개 질문 찾음\n","\n","JSON 36: Psoriasis - 건선의 증상\n","  -> 20개 질문 찾음\n","\n","JSON 37: Psoriasis - 건선의 증상\n","  -> 20개 질문 찾음\n","\n","JSON 38: Psoriasis - 발적\n","  -> 20개 질문 찾음\n","\n","JSON 39: Psoriasis - 흔하지 않은 유형의 건선\n","  -> 20개 질문 찾음\n","\n","JSON 40: Psoriasis - 건선의 진단\n","  -> 20개 질문 찾음\n","\n","JSON 41: Psoriasis - 건선의 치료\n","  -> 20개 질문 찾음\n","\n","JSON 42: Psoriasis - 국소 치료\n","  -> 20개 질문 찾음\n","\n","JSON 43: Psoriasis - 광선요법\n","  -> 20개 질문 찾음\n","\n","JSON 44: Psoriasis - 광선요법\n","  -> 20개 질문 찾음\n","\n","JSON 45: Psoriasis - 광선요법\n","  -> 20개 질문 찾음\n","\n","JSON 46: Psoriasis - 광선요법\n","  -> 20개 질문 찾음\n","\n","JSON 47: Psoriasis - 전신적 치료\n","  -> 20개 질문 찾음\n","\n","JSON 48: Psoriasis - 전신적 치료\n","  -> 20개 질문 찾음\n","\n","JSON 49: Psoriasis - 전신적 치료\n","  -> 20개 질문 찾음\n","\n","JSON 50: Psoriasis - 정의\n","  -> 20개 질문 찾음\n","\n","JSON 51: Psoriasis - 원인\n","  -> 20개 질문 찾음\n","\n","JSON 52: Psoriasis - 증상\n","  -> 20개 질문 찾음\n","\n","JSON 53: Psoriasis - 증상\n","\n","JSON 54: Psoriasis - 진단\n","  -> 20개 질문 찾음\n","\n","JSON 55: Psoriasis - 진단\n","  -> 20개 질문 찾음\n","\n","JSON 56: Psoriasis - 치료\n","  -> 20개 질문 찾음\n","\n","JSON 57: Psoriasis - 치료\n","  -> 20개 질문 찾음\n","\n","JSON 58: Psoriasis - 치료\n","  -> 20개 질문 찾음\n","\n","JSON 59: Psoriasis - 치료\n","  -> 20개 질문 찾음\n","\n","JSON 60: Psoriasis - 주의사항\n","  -> 20개 질문 찾음\n","\n","JSON 61: Psoriasis - 위키요약1\n","  -> 20개 질문 찾음\n","\n","JSON 62: Psoriasis - 위키요약2\n","  -> 20개 질문 찾음\n","\n","JSON 63: Psoriasis - 위키요약3\n","  -> 20개 질문 찾음\n","\n","JSON 64: Psoriasis - 위키요약4\n","  -> 20개 질문 찾음\n","\n","JSON 65: Psoriasis - 위키요약5\n","  -> 20개 질문 찾음\n","\n","JSON 66: Psoriasis - 건선의 정의와 특징\n","  -> 20개 질문 찾음\n","\n","JSON 67: Psoriasis - 건선의 발병 원인과 기전\n","  -> 20개 질문 찾음\n","\n","JSON 68: Psoriasis - 건선의 임상적 분류\n","  -> 20개 질문 찾음\n","\n","JSON 69: Psoriasis - 건선의 진단과 평가\n","  -> 20개 질문 찾음\n","\n","JSON 70: Psoriasis - 건선의 국소 치료\n","  -> 20개 질문 찾음\n","\n","JSON 71: Psoriasis - 건선의 광선 치료\n","  -> 20개 질문 찾음\n","\n","JSON 72: Psoriasis - 건선의 전통적 전신 치료\n","  -> 20개 질문 찾음\n","\n","JSON 73: Psoriasis - 건선의 생물학적 제제\n","  -> 20개 질문 찾음\n","\n","JSON 74: Psoriasis - 건선 관절염\n","  -> 20개 질문 찾음\n","\n","JSON 75: Psoriasis - 건선과 동반 질환\n","  -> 20개 질문 찾음\n","\n","JSON 76: Psoriasis - 건선 환자의 생활 관리\n","  -> 20개 질문 찾음\n","\n","JSON 77: Psoriasis - 소아 건선의 특징\n","  -> 20개 질문 찾음\n","\n","JSON 78: Psoriasis - 건선의 손발톱 병변\n","  -> 20개 질문 찾음\n","\n","JSON 79: Psoriasis - 임신과 건선\n","  -> 20개 질문 찾음\n","\n","JSON 80: Psoriasis - 건선의 최신 치료 동향\n","  -> 20개 질문 찾음\n","\n","총 파싱된 문서 수: 79\n","\n","=== 처리 완료 ===\n","총 1580개의 RAFT 데이터 생성\n","출력 파일: raft_golden_samples02.jsonl\n","\n","라벨별 통계:\n","  Psoriasis:\n","    - 문서 수: 45\n","    - 질문 수: 900\n","    - 문서당 평균 질문 수: 20.0\n","  Rosacea:\n","    - 문서 수: 34\n","    - 질문 수: 680\n","    - 문서당 평균 질문 수: 20.0\n","\n","=== 생성된 데이터 샘플 ===\n","{\n","  \"question_id\": \"rosacea_doc001_q001\",\n","  \"question\": \"주사피부염이 왜 안면과 두피에 주로 발생하는지 이유가 무엇인가요?\",\n","  \"golden_doc\": {\n","    \"doc_id\": \"rosacea_doc_001\",\n","    \"text\": \"주사는 안면과 두피에만 영향을 미칩니다. 이에는 4단계가 있습니다. 주사 전 단계(1단계): 평상시 보다 긴 시간 동안 볼과 코의 피부가 상기되고 따끔거릴 수 있습니다. 혈관 단계(2단계): 표피 바로 밑의 소혈관이 육안으로 관찰되면서 피부가 붉고 부어 보입니다(모세혈관확장증). 염증 단계(3단계): 보통 작은 뾰루지가 생기며, 간혹 고름이 차기도(농포라고 함) 합니다. 후기 단계(4단계): 일부 사람들에서 코 주변의 피부가 간혹 두꺼워져서 붉고 둥글어 보이게 되는 경우도 있습니다(딸기코라고 함). 주사 환자의 안면은 붉어지며 뾰루지와 농포가 발생할 수 있습니다. 이 사진은 혈관 주사가 있는 여성의 볼에 있는 발적 및 모세혈관확장증을 보여줍니다. 이 사진은 염증성 주사가 있는 여성의 선명한 발적 및 작은 고형 뾰루지(구진)를 보여줍니다. 고름(농포)이 포함된 표면 돌기 또한 존재하지만, 희미합니다. 이 사진은 주사 환자에서, 두꺼워진 피부 및 코 비대를 특징으로 하는 딸기코를 보여줍니다. 주사 환자의 안면은 붉어지며 뾰루지와 농포가 발생할 수 있습니다. 이 사진은 혈관 주사가 있는 여성의 볼에 있는 발적 및 모세혈관확장증을 보여줍니다. 이 사진은 염증성 주사가 있는 여성의 선명한 발적 및 작은 고형 뾰루지(구진)를 보여줍니다. 고름(농포)이 포함된 표면 돌기 또한 존재하지만, 희미합니다\",\n","    \"label\": \"Rosacea\",\n","    \"source\": \"MSD Manual\",\n","    \"document_type\": \"oracle\",\n","    \"title\": \"주사의 증상\",\n","    \"text_length\": 673\n","  }\n","}\n"]}]},{"cell_type":"code","source":["import json\n","import re\n","\n","def load_questions_data(questions_file_path):\n","    \"\"\"질문 데이터 텍스트 파일을 로드하고 파싱합니다.\"\"\"\n","    with open(questions_file_path, 'r', encoding='utf-8') as f:\n","        content = f.read()\n","\n","    questions_data = {}\n","\n","    # 전체 내용에서 \"document_N\" 패턴을 모두 찾기\n","    # 더 유연한 패턴 사용\n","    doc_pattern = r'\"document_(\\d+)\":\\s*\\{((?:[^{}]|{[^{}]*})*)\\}'\n","    matches = re.findall(doc_pattern, content, re.DOTALL)\n","\n","    print(f\"정규표현식으로 찾은 문서 수: {len(matches)}\")\n","\n","    # 매치되지 않은 경우를 위한 대안 방법\n","    if len(matches) < 87:  # 예상보다 적으면\n","        print(\"대안 파싱 방법 사용...\")\n","\n","        # 수동으로 \"document_\" 위치 찾기\n","        doc_positions = []\n","        for match in re.finditer(r'\"document_(\\d+)\":', content):\n","            doc_num = int(match.group(1))\n","            start_pos = match.start()\n","            doc_positions.append((doc_num, start_pos))\n","\n","        # 위치 정렬\n","        doc_positions.sort(key=lambda x: x[1])\n","\n","        questions_data = {}\n","        doc_counter = 1\n","        current_category = 'atopic'\n","\n","        for i, (local_doc_num, start_pos) in enumerate(doc_positions):\n","            # 다음 문서의 시작 위치 찾기\n","            if i + 1 < len(doc_positions):\n","                end_pos = doc_positions[i + 1][1]\n","            else:\n","                end_pos = len(content)\n","\n","            # 해당 문서의 전체 내용 추출\n","            doc_content = content[start_pos:end_pos]\n","\n","            # 카테고리 판단 (아토피는 1-51, 지루성은 1-36이지만 두 번째 그룹)\n","            # 새로운 JSON 객체가 시작되는지 확인\n","            if '},\\n{' in content[max(0, start_pos-100):start_pos]:\n","                current_category = 'seborrheic'\n","\n","            # text 추출\n","            text_match = re.search(r'\"text\":\\s*\"(.*?)\",\\s*\"queries\"', doc_content, re.DOTALL)\n","            if text_match:\n","                text = text_match.group(1)\n","            else:\n","                continue\n","\n","            # queries 추출\n","            queries_match = re.search(r'\"queries\":\\s*\\[(.*?)\\]\\s*\\}', doc_content, re.DOTALL)\n","            if queries_match:\n","                queries_content = queries_match.group(1)\n","                # 개별 query 추출 (더 정확한 패턴)\n","                queries = []\n","                for query_match in re.finditer(r'\"([^\"]+)\"', queries_content):\n","                    queries.append(query_match.group(1))\n","            else:\n","                queries = []\n","\n","            questions_data[f\"document_{doc_counter}\"] = {\n","                'text': text,\n","                'queries': queries,\n","                'category': current_category,\n","                'local_doc_num': local_doc_num\n","            }\n","            doc_counter += 1\n","\n","            # 아토피에서 지루성으로 넘어가는 지점 체크 (더 정확한 방법)\n","            if current_category == 'atopic' and local_doc_num == 51:\n","                current_category = 'seborrheic'\n","\n","        return questions_data\n","\n","    # 원래 방법이 성공한 경우\n","    doc_counter = 1\n","    current_category = 'atopic'\n","\n","    for local_doc_num_str, doc_content in matches:\n","        local_doc_num = int(local_doc_num_str)\n","\n","        # 카테고리 전환 점검\n","        if current_category == 'atopic' and local_doc_num == 1 and doc_counter > 51:\n","            current_category = 'seborrheic'\n","\n","        # text 추출\n","        text_match = re.search(r'\"text\":\\s*\"(.*?)\",', doc_content, re.DOTALL)\n","        if text_match:\n","            text = text_match.group(1)\n","        else:\n","            continue\n","\n","        # queries 추출\n","        queries_match = re.search(r'\"queries\":\\s*\\[(.*?)\\]', doc_content, re.DOTALL)\n","        if queries_match:\n","            queries_content = queries_match.group(1)\n","            queries = re.findall(r'\"([^\"]*)\"', queries_content)\n","        else:\n","            queries = []\n","\n","        questions_data[f\"document_{doc_counter}\"] = {\n","            'text': text,\n","            'queries': queries,\n","            'category': current_category,\n","            'local_doc_num': local_doc_num\n","        }\n","        doc_counter += 1\n","\n","    return questions_data\n","\n","def load_metadata(metadata_file_path):\n","    \"\"\"메타데이터 파일을 파싱합니다.\"\"\"\n","    with open(metadata_file_path, 'r', encoding='utf-8') as f:\n","        content = f.read()\n","\n","    metadata_docs = []\n","\n","    # LABEL로 섹션 분리\n","    sections = re.split(r'={80,}\\nLABEL: ([^(]+)', content)[1:]\n","\n","    for i in range(0, len(sections), 2):\n","        if i + 1 < len(sections):\n","            label = sections[i].strip()\n","            section_content = sections[i + 1]\n","\n","            # 카테고리 판단\n","            category = 'atopic' if 'Atopic' in label else 'seborrheic'\n","\n","            # 각 문서별로 분리\n","            docs = re.split(r'\\[문서 (\\d+)\\]', section_content)[1:]\n","\n","            for j in range(0, len(docs), 2):\n","                if j + 1 < len(docs):\n","                    doc_num = docs[j].strip()\n","                    doc_content = docs[j + 1]\n","\n","                    doc_info = {\n","                        'label': label,\n","                        'doc_number': int(doc_num),\n","                        'category': category\n","                    }\n","\n","                    lines = doc_content.strip().split('\\n')\n","                    text_lines = []\n","                    collecting_text = False\n","\n","                    for line in lines:\n","                        if line.startswith('Label:'):\n","                            doc_info['label'] = line.split(':', 1)[1].strip()\n","                        elif line.startswith('Source:'):\n","                            doc_info['source'] = line.split(':', 1)[1].strip()\n","                        elif line.startswith('Title:'):\n","                            doc_info['title'] = line.split(':', 1)[1].strip()\n","                        elif line.startswith('Document Type:'):\n","                            doc_info['document_type'] = line.split(':', 1)[1].strip()\n","                        elif line.startswith('Text Length:'):\n","                            doc_info['text_length'] = int(line.split(':', 1)[1].strip())\n","                        elif line.startswith('Text:'):\n","                            text_lines.append(line.split(':', 1)[1].strip())\n","                            collecting_text = True\n","                        elif collecting_text and line.startswith('---'):\n","                            collecting_text = False\n","                        elif collecting_text:\n","                            text_lines.append(line.strip())\n","\n","                    if text_lines:\n","                        doc_info['text'] = ' '.join(text_lines).strip()\n","\n","                    metadata_docs.append(doc_info)\n","\n","    return metadata_docs\n","\n","def match_text_with_metadata(questions_data, metadata_docs):\n","    \"\"\"질문 데이터의 텍스트와 메타데이터를 매칭합니다.\"\"\"\n","    matched_data = []\n","\n","    for doc_key, doc_data in questions_data.items():\n","        question_text = doc_data['text']\n","        queries = doc_data['queries']\n","        category = doc_data['category']\n","        local_doc_num = doc_data['local_doc_num']\n","\n","        # 같은 카테고리의 메타데이터에서 매칭\n","        matched_metadata = None\n","        for meta_doc in metadata_docs:\n","            if (meta_doc['category'] == category and\n","                meta_doc['doc_number'] == local_doc_num and\n","                'text' in meta_doc):\n","                matched_metadata = meta_doc\n","                break\n","\n","        # 텍스트 기반 매칭 (번호 매칭이 실패한 경우)\n","        if not matched_metadata:\n","            for meta_doc in metadata_docs:\n","                if (meta_doc['category'] == category and 'text' in meta_doc):\n","                    if (question_text in meta_doc['text'] or\n","                        meta_doc['text'] in question_text or\n","                        re.sub(r'\\s+', '', question_text) in re.sub(r'\\s+', '', meta_doc['text'])):\n","                        matched_metadata = meta_doc\n","                        break\n","\n","        if matched_metadata:\n","            doc_number = int(doc_key.split('_')[1])\n","\n","            matched_data.append({\n","                'doc_number': doc_number,\n","                'local_doc_num': local_doc_num,\n","                'category': category,\n","                'original_text': question_text,\n","                'queries': queries,\n","                'metadata': matched_metadata\n","            })\n","        else:\n","            print(f\"Warning: No metadata found for {doc_key} (category: {category}, local_num: {local_doc_num})\")\n","\n","    return matched_data\n","\n","def generate_golden_samples(matched_data, output_file_path):\n","    \"\"\"골든 샘플을 생성하고 JSONL 파일로 저장합니다.\"\"\"\n","\n","    with open(output_file_path, 'w', encoding='utf-8') as f:\n","        for doc_data in matched_data:\n","            doc_number = doc_data['doc_number']\n","            local_doc_num = doc_data['local_doc_num']\n","            category = doc_data['category']\n","            queries = doc_data['queries']\n","            metadata = doc_data['metadata']\n","\n","            for i, question in enumerate(queries, 1):\n","                question_id = f\"{category}_doc{doc_number:03d}_q{i:03d}\"\n","                doc_id = f\"{category}_doc_{doc_number:03d}\"\n","\n","                golden_sample = {\n","                    \"question_id\": question_id,\n","                    \"question\": question,\n","                    \"golden_doc\": {\n","                        \"doc_id\": doc_id,\n","                        \"text\": metadata['text'],\n","                        \"label\": metadata['label'],\n","                        \"source\": metadata.get('source', ''),\n","                        \"document_type\": metadata.get('document_type', ''),\n","                        \"title\": metadata.get('title', ''),\n","                        \"text_length\": metadata.get('text_length', len(metadata['text']))\n","                    }\n","                }\n","\n","                f.write(json.dumps(golden_sample, ensure_ascii=False) + '\\n')\n","\n","def main():\n","    \"\"\"메인 실행 함수\"\"\"\n","    questions_file_path = \"Q03.txt\"\n","    metadata_file_path = \"atopic_seborrheic_docs.txt\"\n","    output_file_path = \"raft_golden_samples03.jsonl\"\n","\n","    print(\"질문 데이터를 로딩 중...\")\n","    questions_data = load_questions_data(questions_file_path)\n","    print(f\"로드된 질문 문서 수: {len(questions_data)}\")\n","\n","    atopic_count = sum(1 for doc in questions_data.values() if doc['category'] == 'atopic')\n","    seborrheic_count = sum(1 for doc in questions_data.values() if doc['category'] == 'seborrheic')\n","    print(f\"아토피 문서: {atopic_count}개, 지루성 문서: {seborrheic_count}개\")\n","\n","    print(\"메타데이터를 파싱 중...\")\n","    metadata_docs = load_metadata(metadata_file_path)\n","    print(f\"로드된 메타데이터 문서 수: {len(metadata_docs)}\")\n","\n","    print(\"텍스트와 메타데이터를 매칭 중...\")\n","    matched_data = match_text_with_metadata(questions_data, metadata_docs)\n","    print(f\"매칭된 문서 수: {len(matched_data)}\")\n","\n","    print(\"골든 샘플을 생성 중...\")\n","    generate_golden_samples(matched_data, output_file_path)\n","\n","    total_samples = sum(len(doc['queries']) for doc in matched_data)\n","    print(f\"작업 완료! {len(matched_data)} 개 문서에서 총 {total_samples} 개의 골든 샘플이 생성되었습니다.\")\n","    print(f\"결과 파일: {output_file_path}\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r44UCikH3w6d","executionInfo":{"status":"ok","timestamp":1764040916597,"user_tz":-540,"elapsed":88,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"770adb05-80f7-476b-dd0a-fe15828d5392"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["질문 데이터를 로딩 중...\n","정규표현식으로 찾은 문서 수: 83\n","대안 파싱 방법 사용...\n","로드된 질문 문서 수: 83\n","아토피 문서: 51개, 지루성 문서: 32개\n","메타데이터를 파싱 중...\n","로드된 메타데이터 문서 수: 87\n","텍스트와 메타데이터를 매칭 중...\n","매칭된 문서 수: 83\n","골든 샘플을 생성 중...\n","작업 완료! 83 개 문서에서 총 1660 개의 골든 샘플이 생성되었습니다.\n","결과 파일: raft_golden_samples03.jsonl\n"]}]},{"cell_type":"code","source":["import json\n","\n","def fix_seborrheic_doc_numbers(input_file, output_file):\n","    \"\"\"seborrheic 문서들의 question_id와 doc_id에서 51을 빼는 함수\"\"\"\n","\n","    with open(input_file, 'r', encoding='utf-8') as f_in, \\\n","         open(output_file, 'w', encoding='utf-8') as f_out:\n","\n","        for line in f_in:\n","            data = json.loads(line.strip())\n","\n","            # seborrheic 문서만 처리\n","            if data['question_id'].startswith('seborrheic_'):\n","                # question_id에서 숫자 추출하고 51 빼기\n","                question_parts = data['question_id'].split('_')\n","                doc_part = question_parts[1]  # \"doc083\" 형태\n","                doc_num = int(doc_part[3:])   # 083 -> 83\n","                new_doc_num = doc_num - 51    # 83 - 51 = 32\n","\n","                # 새로운 question_id 생성\n","                data['question_id'] = f\"seborrheic_doc{new_doc_num:03d}_{question_parts[2]}\"\n","\n","                # doc_id에서도 51 빼기\n","                doc_id_parts = data['golden_doc']['doc_id'].split('_')\n","                doc_id_num = int(doc_id_parts[2])  # \"seborrheic_doc_083\" -> 83\n","                new_doc_id_num = doc_id_num - 51   # 83 - 51 = 32\n","\n","                # 새로운 doc_id 생성\n","                data['golden_doc']['doc_id'] = f\"seborrheic_doc_{new_doc_id_num:03d}\"\n","\n","            # 수정된 데이터를 출력 파일에 쓰기\n","            f_out.write(json.dumps(data, ensure_ascii=False) + '\\n')\n","\n","# 실행\n","input_file = \"raft_golden_samples03.jsonl\"      # 원본 파일명\n","output_file = \"raft_golden_samples_fixed03.jsonl\"  # 수정된 파일명\n","\n","fix_seborrheic_doc_numbers(input_file, output_file)\n","print(\"seborrheic 문서 번호 수정 완료!\")\n","print(f\"수정된 파일: {output_file}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"IcjwqXaIDWdi","executionInfo":{"status":"ok","timestamp":1764041273389,"user_tz":-540,"elapsed":107,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"f01afc2c-ceb7-44a6-d4de-14705808b097"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["seborrheic 문서 번호 수정 완료!\n","수정된 파일: raft_golden_samples_fixed03.jsonl\n"]}]},{"cell_type":"code","source":["import shutil\n","\n","def merge_jsonl_files(file1, file2, output_file):\n","    \"\"\"두 개의 JSONL 파일을 하나로 합치기\"\"\"\n","    with open(output_file, 'w', encoding='utf-8') as outfile:\n","        with open(file1, 'r', encoding='utf-8') as infile1:\n","            shutil.copyfileobj(infile1, outfile)\n","        with open(file2, 'r', encoding='utf-8') as infile2:\n","            shutil.copyfileobj(infile2, outfile)\n","\n","# 실행\n","merge_jsonl_files(\"merged.jsonl\", \"raft_golden_samples_fixed03.jsonl\", \"raft_golden_samples_final.jsonl\")\n","print(\"파일 합치기 완료!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3VmLlyOELmV","executionInfo":{"status":"ok","timestamp":1764041567545,"user_tz":-540,"elapsed":18,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"355c760d-92ee-408e-e024-84c591ad802e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["파일 합치기 완료!\n"]}]},{"cell_type":"code","source":["import shutil\n","import json\n","from collections import Counter\n","\n","def merge_three_jsonl_files(file1, file2, file3, output_file):\n","    \"\"\"세 개의 JSONL 파일을 하나로 합치기\"\"\"\n","    with open(output_file, 'w', encoding='utf-8') as outfile:\n","        with open(file1, 'r', encoding='utf-8') as infile1:\n","            shutil.copyfileobj(infile1, outfile)\n","        with open(file2, 'r', encoding='utf-8') as infile2:\n","            shutil.copyfileobj(infile2, outfile)\n","        with open(file3, 'r', encoding='utf-8') as infile3:\n","            shutil.copyfileobj(infile3, outfile)\n","\n","def count_labels_in_merged_file(jsonl_file):\n","    \"\"\"합쳐진 JSONL 파일에서 golden label들을 카운트하는 함수\"\"\"\n","\n","    label_counts = Counter()\n","\n","    with open(jsonl_file, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            data = json.loads(line.strip())\n","            label = data['golden_doc']['label']\n","            label_counts[label] += 1\n","\n","    # 결과 출력\n","    print(f\"\\n=== 합쳐진 파일 통계 ===\")\n","    print(f\"총 샘플 수: {sum(label_counts.values())}\")\n","    print(f\"라벨 종류: {len(label_counts)}\")\n","    print(\"\\n라벨별 개수:\")\n","    print(\"-\" * 40)\n","\n","    for label, count in label_counts.most_common():\n","        print(f\"{label}: {count}개\")\n","\n","    return label_counts\n","\n","# 실행\n","merge_three_jsonl_files(\"raft_golden_samples01.jsonl\", \"raft_golden_samples02.jsonl\", \"raft_golden_samples_fixed03.jsonl\", \"raft_golden_samples_final01.jsonl\")\n","print(\"파일 합치기 완료!\")\n","\n","# 합쳐진 파일의 라벨 통계 출력\n","count_labels_in_merged_file(\"raft_golden_samples_final01.jsonl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"54hGNroQjnnl","executionInfo":{"status":"ok","timestamp":1764049862528,"user_tz":-540,"elapsed":60,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"b992b9e8-cad3-4719-d30f-d67d81a064e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["파일 합치기 완료!\n","\n","=== 합쳐진 파일 통계 ===\n","총 샘플 수: 4460\n","라벨 종류: 5\n","\n","라벨별 개수:\n","----------------------------------------\n","Acne: 1220개\n","Atopic Dermatitis: 1020개\n","Psoriasis: 900개\n","Rosacea: 680개\n","Seborrheic Dermatitis: 640개\n"]},{"output_type":"execute_result","data":{"text/plain":["Counter({'Acne': 1220,\n","         'Rosacea': 680,\n","         'Psoriasis': 900,\n","         'Atopic Dermatitis': 1020,\n","         'Seborrheic Dermatitis': 640})"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["##**네거티브 샘플 제작**"],"metadata":{"id":"amFY1P7DHtnm"}},{"cell_type":"code","source":["import json\n","import random\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","\n","# 도메인 지식 기반 Hard Negative 매핑\n","HARD_NEGATIVE_MAPPING = {\n","    \"Acne\": [\"Rosacea\", \"Seborrheic Dermatitis\"],\n","    \"Rosacea\": [\"Acne\", \"Seborrheic Dermatitis\", \"Atopic Dermatitis\"],\n","    \"Atopic Dermatitis\": [\"Seborrheic Dermatitis\", \"Psoriasis\", \"Rosacea\"],\n","    \"Psoriasis\": [\"Seborrheic Dermatitis\", \"Atopic Dermatitis\"],\n","    \"Seborrheic Dermatitis\": [\"Psoriasis\", \"Atopic Dermatitis\", \"Acne\", \"Rosacea\"]\n","}\n","\n","def load_golden_samples(golden_file):\n","    \"\"\"골든 샘플 JSONL 파일 로드\"\"\"\n","    golden_samples = []\n","    with open(golden_file, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            data = json.loads(line.strip())\n","            golden_samples.append(data)\n","    return golden_samples\n","\n","def load_candidate_samples(candidate_file):\n","    \"\"\"후보 샘플 JSONL 파일 로드\"\"\"\n","    oracle_samples = []  # Hard negative 용\n","    distractor_samples = []  # Easy negative 용\n","\n","    with open(candidate_file, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            data = json.loads(line.strip())\n","            if data['document_type'] == 'oracle':\n","                oracle_samples.append(data)\n","            elif data['document_type'] == 'distractor':\n","                distractor_samples.append(data)\n","\n","    return oracle_samples, distractor_samples\n","\n","def calculate_similarity(query_text, candidate_texts):\n","    \"\"\"TF-IDF 기반 유사도 계산\"\"\"\n","    texts = [query_text] + candidate_texts\n","    vectorizer = TfidfVectorizer(stop_words=None, max_features=1000)\n","\n","    try:\n","        tfidf_matrix = vectorizer.fit_transform(texts)\n","        query_vector = tfidf_matrix[0]\n","        candidate_vectors = tfidf_matrix[1:]\n","\n","        similarities = cosine_similarity(query_vector, candidate_vectors)[0]\n","        return similarities\n","    except:\n","        # 텍스트가 너무 적거나 문제가 있을 때 랜덤 점수 반환\n","        return np.random.random(len(candidate_texts))\n","\n","def get_hard_negatives(golden_sample, oracle_samples):\n","    \"\"\"Hard negative 3개 선택\"\"\"\n","    golden_label = golden_sample['golden_doc']['label']\n","    query_text = golden_sample['question']\n","\n","    # 도메인 지식으로 후보 라벨 선정\n","    if golden_label not in HARD_NEGATIVE_MAPPING:\n","        print(f\"Warning: {golden_label} not in mapping, using random selection\")\n","        candidate_labels = list(set([sample['label'] for sample in oracle_samples]))\n","        candidate_labels = [label for label in candidate_labels if label != golden_label]\n","        hard_negative_labels = random.sample(candidate_labels, min(3, len(candidate_labels)))\n","    else:\n","        hard_negative_labels = HARD_NEGATIVE_MAPPING[golden_label]\n","\n","    # 해당 라벨의 후보 샘플들 수집\n","    candidate_samples = []\n","    for sample in oracle_samples:\n","        if sample['label'] in hard_negative_labels:\n","            candidate_samples.append(sample)\n","\n","    if len(candidate_samples) < 3:\n","        print(f\"Warning: Not enough candidates for {golden_label}, found {len(candidate_samples)}\")\n","        # 부족한 경우 다른 라벨에서도 가져오기\n","        other_samples = [sample for sample in oracle_samples if sample['label'] != golden_label]\n","        candidate_samples.extend(other_samples[:3-len(candidate_samples)])\n","\n","    # 유사도 계산 및 상위 3개 선택\n","    if len(candidate_samples) > 3:\n","        candidate_texts = [sample['text'] for sample in candidate_samples]\n","        similarities = calculate_similarity(query_text, candidate_texts)\n","\n","        # 유사도 기준으로 정렬하고 상위 3개 선택\n","        sorted_indices = np.argsort(similarities)[::-1]\n","        selected_samples = [candidate_samples[i] for i in sorted_indices[:3]]\n","    else:\n","        selected_samples = candidate_samples[:3]\n","\n","    return selected_samples\n","\n","def get_easy_negative(distractor_samples):\n","    \"\"\"Easy negative 1개 랜덤 선택\"\"\"\n","    if distractor_samples:\n","        return random.choice(distractor_samples)\n","    else:\n","        return None\n","\n","def generate_raft_samples(golden_file, candidate_file, output_file):\n","    \"\"\"RAFT 샘플 생성 메인 함수\"\"\"\n","\n","    print(\"데이터 로딩 중...\")\n","    golden_samples = load_golden_samples(golden_file)\n","    oracle_samples, distractor_samples = load_candidate_samples(candidate_file)\n","\n","    print(f\"골든 샘플: {len(golden_samples)}개\")\n","    print(f\"오라클 샘플: {len(oracle_samples)}개\")\n","    print(f\"디스트랙터 샘플: {len(distractor_samples)}개\")\n","\n","    raft_samples = []\n","\n","    for i, golden_sample in enumerate(golden_samples):\n","        if i % 100 == 0:\n","            print(f\"처리 중: {i+1}/{len(golden_samples)}\")\n","\n","        # Hard negatives 선택\n","        hard_negatives = get_hard_negatives(golden_sample, oracle_samples)\n","\n","        # Easy negative 선택\n","        easy_negative = get_easy_negative(distractor_samples)\n","\n","        # RAFT 형태로 구성\n","        raft_sample = {\n","            \"query\": golden_sample['question'],\n","            \"golden\": {\n","                \"label\": golden_sample['golden_doc']['label'],\n","                \"text\": golden_sample['golden_doc']['text'],\n","                \"source\": golden_sample['golden_doc']['source'],\n","                \"title\": golden_sample['golden_doc']['title'],\n","                \"document_type\": golden_sample['golden_doc']['document_type'],\n","                \"text_length\": golden_sample['golden_doc']['text_length']\n","            },\n","            \"hard_negatives\": hard_negatives\n","        }\n","\n","        # Easy negative가 있으면 추가\n","        if easy_negative:\n","            raft_sample[\"easy_negative\"] = easy_negative\n","\n","        raft_samples.append(raft_sample)\n","\n","    # 결과 저장\n","    with open(output_file, 'w', encoding='utf-8') as f:\n","        for sample in raft_samples:\n","            f.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n","\n","    print(f\"완료! {len(raft_samples)}개의 RAFT 샘플이 {output_file}에 저장되었습니다.\")\n","\n","    # 통계 출력\n","    labels = [sample['golden']['label'] for sample in raft_samples]\n","    label_counts = {}\n","    for label in labels:\n","        label_counts[label] = label_counts.get(label, 0) + 1\n","\n","    print(\"\\n라벨별 샘플 수:\")\n","    for label, count in label_counts.items():\n","        print(f\"  {label}: {count}개\")\n","\n","def main():\n","    # 파일 경로 설정\n","    golden_file = \"raft_golden_samples_final01.jsonl\"      # 기존 골든 샘플 파일\n","    candidate_file = \"raft_dataset_final.jsonl\"  # 모든 후보 샘플 파일 (oracle + distractor)\n","    output_file = \"raft_samples.jsonl\"       # 최종 RAFT 샘플 파일\n","\n","    generate_raft_samples(golden_file, candidate_file, output_file)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mc-6DxbLH0rq","executionInfo":{"status":"ok","timestamp":1764049968351,"user_tz":-540,"elapsed":46205,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"692903a4-532a-44e0-ad3b-59f9946b48e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["데이터 로딩 중...\n","골든 샘플: 4460개\n","오라클 샘플: 236개\n","디스트랙터 샘플: 109개\n","처리 중: 1/4460\n","처리 중: 101/4460\n","처리 중: 201/4460\n","처리 중: 301/4460\n","처리 중: 401/4460\n","처리 중: 501/4460\n","처리 중: 601/4460\n","처리 중: 701/4460\n","처리 중: 801/4460\n","처리 중: 901/4460\n","처리 중: 1001/4460\n","처리 중: 1101/4460\n","처리 중: 1201/4460\n","처리 중: 1301/4460\n","처리 중: 1401/4460\n","처리 중: 1501/4460\n","처리 중: 1601/4460\n","처리 중: 1701/4460\n","처리 중: 1801/4460\n","처리 중: 1901/4460\n","처리 중: 2001/4460\n","처리 중: 2101/4460\n","처리 중: 2201/4460\n","처리 중: 2301/4460\n","처리 중: 2401/4460\n","처리 중: 2501/4460\n","처리 중: 2601/4460\n","처리 중: 2701/4460\n","처리 중: 2801/4460\n","처리 중: 2901/4460\n","처리 중: 3001/4460\n","처리 중: 3101/4460\n","처리 중: 3201/4460\n","처리 중: 3301/4460\n","처리 중: 3401/4460\n","처리 중: 3501/4460\n","처리 중: 3601/4460\n","처리 중: 3701/4460\n","처리 중: 3801/4460\n","처리 중: 3901/4460\n","처리 중: 4001/4460\n","처리 중: 4101/4460\n","처리 중: 4201/4460\n","처리 중: 4301/4460\n","처리 중: 4401/4460\n","완료! 4460개의 RAFT 샘플이 raft_samples.jsonl에 저장되었습니다.\n","\n","라벨별 샘플 수:\n","  Acne: 1220개\n","  Rosacea: 680개\n","  Psoriasis: 900개\n","  Atopic Dermatitis: 1020개\n","  Seborrheic Dermatitis: 640개\n"]}]},{"cell_type":"code","source":["import json\n","from collections import Counter\n","\n","def count_labels(jsonl_file):\n","    \"\"\"JSONL 파일에서 golden label들을 카운트하는 함수\"\"\"\n","\n","    label_counts = Counter()\n","\n","    with open(jsonl_file, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            data = json.loads(line.strip())\n","            label = data['golden']['label']\n","            label_counts[label] += 1\n","\n","    # 결과 출력\n","    print(f\"총 샘플 수: {sum(label_counts.values())}\")\n","    print(f\"라벨 종류: {len(label_counts)}\")\n","    print(\"\\n라벨별 개수:\")\n","    print(\"-\" * 40)\n","\n","    for label, count in label_counts.most_common():\n","        print(f\"{label}: {count}개\")\n","\n","    return label_counts\n","\n","# 실행\n","if __name__ == \"__main__\":\n","    jsonl_file = \"raft_samples.jsonl\"  # 파일명을 실제 파일로 변경\n","    count_labels(jsonl_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1w_T7XYji4g5","executionInfo":{"status":"ok","timestamp":1764049983566,"user_tz":-540,"elapsed":160,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"60067fd7-3a81-411f-b2c8-e4d0e56198d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["총 샘플 수: 4460\n","라벨 종류: 5\n","\n","라벨별 개수:\n","----------------------------------------\n","Acne: 1220개\n","Atopic Dermatitis: 1020개\n","Psoriasis: 900개\n","Rosacea: 680개\n","Seborrheic Dermatitis: 640개\n"]}]},{"cell_type":"markdown","source":["##**짧은 텍스트 쳐 내**"],"metadata":{"id":"L8intyGHmJKo"}},{"cell_type":"code","source":["import json\n","\n","def show_shortest_texts(jsonl_file, top_n=40):\n","    \"\"\"JSONL 파일에서 text_length가 가장 짧은 상위 N개의 text 출력\"\"\"\n","\n","    samples = []\n","\n","    # 모든 샘플 읽기\n","    with open(jsonl_file, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            data = json.loads(line.strip())\n","            samples.append({\n","                'text_length': data['golden']['text_length'],  # golden_doc → golden\n","                'text': data['golden']['text'],\n","                'label': data['golden']['label'],\n","                'query': data['query']  # question_id → query\n","            })\n","\n","    # text_length 기준으로 오름차순 정렬\n","    samples.sort(key=lambda x: x['text_length'])\n","\n","    # 상위 N개 출력\n","    print(f\"=== text_length가 가장 짧은 상위 {top_n}개 ===\\n\")\n","\n","    for i, sample in enumerate(samples[:top_n], 1):\n","        print(f\"{i}. [{sample['label']}] text_length: {sample['text_length']}\")\n","        print(f\"   query: {sample['query'][:60]}...\")  # 질문 앞부분만 출력\n","        print(f\"   text: {sample['text']}\")\n","        print(\"-\" * 80)\n","\n","# 실행\n","if __name__ == \"__main__\":\n","    jsonl_file = \"raft_samples.jsonl\"  # 실제 파일명으로 변경\n","    show_shortest_texts(jsonl_file, 40)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ICjdGwONmIGh","executionInfo":{"status":"ok","timestamp":1764051569636,"user_tz":-540,"elapsed":161,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"64212582-6895-409c-e174-e1a3b1fe3be6","collapsed":true},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["=== text_length가 가장 짧은 상위 40개 ===\n","\n","1. [Rosacea] text_length: 9\n","   query: 주사피부염의 원인이 불명이라는 것은 어떤 의미인가요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","2. [Rosacea] text_length: 9\n","   query: 원인을 알 수 없는데도 진단이 가능한 이유는 무엇인가요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","3. [Rosacea] text_length: 9\n","   query: 원인이 밝혀지지 않은 질환은 어떤 방식으로 치료하나요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","4. [Rosacea] text_length: 9\n","   query: 주사가 원인을 특정할 수 없다는 점이 관리에 어떤 영향을 주나요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","5. [Rosacea] text_length: 9\n","   query: 원인을 모르는 상태에서 증상 조절이 중요한 이유는 무엇인가요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","6. [Rosacea] text_length: 9\n","   query: 원인이 불명인 질환은 어떤 요인들을 의심하게 되나요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","7. [Rosacea] text_length: 9\n","   query: 원인을 찾지 못하는 이유는 무엇인가요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","8. [Rosacea] text_length: 9\n","   query: 원인이 불명일 때 환자에게 어떤 설명을 하게 되나요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","9. [Rosacea] text_length: 9\n","   query: 원인이 밝혀지지 않은 피부질환의 공통적인 특징은 무엇인가요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","10. [Rosacea] text_length: 9\n","   query: 주사피부염의 원인이 확실하지 않아 진단이 어려운가요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","11. [Rosacea] text_length: 9\n","   query: 원인을 모르지만 악화 요인을 파악해야 하는 이유는 무엇인가요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","12. [Rosacea] text_length: 9\n","   query: 원인이 불명인 경우 환자의 생활 습관은 어떻게 관리해야 하나요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","13. [Rosacea] text_length: 9\n","   query: 원인이 불명이어도 증상이 반복되는 이유는 무엇인가요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","14. [Rosacea] text_length: 9\n","   query: 원인이 불명인 질환에서 예후는 어떻게 판단하나요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","15. [Rosacea] text_length: 9\n","   query: 원인이 불명인데도 특정 환자군에서 많이 발생하는 이유는 무엇인가요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","16. [Rosacea] text_length: 9\n","   query: 원인을 규명하기 위한 연구는 어떤 방향으로 이루어지나요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","17. [Rosacea] text_length: 9\n","   query: 원인이 불명이라고 해서 치료가 불가능한가요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","18. [Rosacea] text_length: 9\n","   query: 원인이 불명인 질환에서 오진 위험은 증가하나요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","19. [Rosacea] text_length: 9\n","   query: 원인을 알 수 없다는 것이 치료 선택에 어떤 제약을 주나요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","20. [Rosacea] text_length: 9\n","   query: 원인이 불명인 경우 환자는 어떤 부분에 주의해야 하나요?...\n","   text: 원인은 불명이다.\n","--------------------------------------------------------------------------------\n","21. [Psoriasis] text_length: 13\n","   query: 건선이 전염되지 않는 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","22. [Psoriasis] text_length: 13\n","   query: 건선이 감염성 질환으로 오해받는 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","23. [Psoriasis] text_length: 13\n","   query: 비전염성 질환임에도 외관 때문에 오해가 생기는 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","24. [Psoriasis] text_length: 13\n","   query: 건선을 전염병과 구분해야 하는 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","25. [Psoriasis] text_length: 13\n","   query: 비전염성임에도 예방 조치가 필요한 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","26. [Psoriasis] text_length: 13\n","   query: 전염되지 않지만 가족력이 있는 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","27. [Psoriasis] text_length: 13\n","   query: 자가면역질환이 전염되지 않는 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","28. [Psoriasis] text_length: 13\n","   query: 건선 환자가 사회적 오해를 겪는 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","29. [Psoriasis] text_length: 13\n","   query: 비전염성이라는 사실이 환자 교육에서 중요한 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","30. [Psoriasis] text_length: 13\n","   query: 건선을 접촉 피부염과 구별해야 하는 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","31. [Psoriasis] text_length: 13\n","   query: 건선 환자를 격리할 필요가 없는 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","32. [Psoriasis] text_length: 13\n","   query: 전염 위험이 없어도 치료가 필요한 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","33. [Psoriasis] text_length: 13\n","   query: 건선이 외관상 전염처럼 보일 수 있는 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","34. [Psoriasis] text_length: 13\n","   query: 감염성 질환과 달리 건선이 항생제로 치료되지 않는 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","35. [Psoriasis] text_length: 13\n","   query: 비전염성이라는 점이 치료 접근 방식에 어떤 영향을 주나요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","36. [Psoriasis] text_length: 13\n","   query: 건선 환자가 긍정적 사회적 지지를 필요로 하는 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","37. [Psoriasis] text_length: 13\n","   query: 전염이 아니라는 정보가 환자 심리에 어떤 영향을 주나요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","38. [Psoriasis] text_length: 13\n","   query: 비전염성 질환의 공중보건적 의미는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","39. [Psoriasis] text_length: 13\n","   query: 건선 환자 주변인이 안심해야 하는 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n","40. [Psoriasis] text_length: 13\n","   query: 건선의 비전염성을 홍보하는 것이 필요한 이유는 무엇인가요?...\n","   text: 건선은 전염되지 않는다.\n","--------------------------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["import json\n","\n","def show_short_texts_unique(jsonl_file, max_length=50):\n","    \"\"\"JSONL 파일에서 text_length가 지정값 이하인 텍스트들을 중복 제거하여 출력\"\"\"\n","\n","    seen_texts = set()  # 중복 체크용\n","    short_samples = []\n","\n","    # 모든 샘플 읽기\n","    with open(jsonl_file, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            data = json.loads(line.strip())\n","            text_length = data['golden']['text_length']\n","            text = data['golden']['text']\n","\n","            # 길이 조건 확인 및 중복 체크\n","            if text_length <= max_length and text not in seen_texts:\n","                seen_texts.add(text)\n","                short_samples.append({\n","                    'text_length': text_length,\n","                    'text': text,\n","                    'label': data['golden']['label'],\n","                    'query': data['query']\n","                })\n","\n","    # text_length 기준으로 오름차순 정렬\n","    short_samples.sort(key=lambda x: x['text_length'])\n","\n","    # 결과 출력\n","    print(f\"=== text_length {max_length} 이하인 고유 텍스트 ({len(short_samples)}개) ===\\n\")\n","\n","    for i, sample in enumerate(short_samples, 1):\n","        print(f\"{i}. [{sample['label']}] text_length: {sample['text_length']}\")\n","        print(f\"   query: {sample['query'][:60]}...\")\n","        print(f\"   text: {sample['text']}\")\n","        print(\"-\" * 80)\n","\n","# 실행\n","if __name__ == \"__main__\":\n","    jsonl_file = \"raft_samples_filtered.jsonl\"  # 실제 파일명으로 변경\n","    show_short_texts_unique(jsonl_file, 60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"wAvDsI92rFpw","executionInfo":{"status":"ok","timestamp":1764051916709,"user_tz":-540,"elapsed":114,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"b6c64695-9ad4-4dd4-cdcf-62672d3fa809"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["=== text_length 60 이하인 고유 텍스트 (6개) ===\n","\n","1. [Psoriasis] text_length: 51\n","   query: 건선이 뇌졸중 위험 증가와 연관되는 이유는 무엇인가요?...\n","   text: 그러나 건선은 뇌졸중의 위험 증가와 연관되며 높은 혈중 수준의 치료를 통해 개선할 수 있다.\n","--------------------------------------------------------------------------------\n","2. [Atopic Dermatitis] text_length: 51\n","   query: 유아 아토피의 주요 원인이 음식인 이유는 무엇인가요?...\n","   text: 유아의 경우 대부분 음식에서 비롯되지만 그 기전이 일반적인 음식 알레르기성 피부염과 다르다.\n","--------------------------------------------------------------------------------\n","3. [Atopic Dermatitis] text_length: 52\n","   query: 사춘기 아토피의 특징은 무엇인가요?...\n","   text: 사춘기와 성인기에는 피부 건조, 손발 유두 습진, 태선화 등 소아기와 비슷한 분포를 보입니다.\n","--------------------------------------------------------------------------------\n","4. [Atopic Dermatitis] text_length: 53\n","   query: 음식물 유발 검사 후 증상이 없으면 안심해도 되나요?...\n","   text: 검사 후에 환자에게 아무런 증상이 나타나지 않으면 임상적으로 원인 음식물이 아니라고 판정합니다.\n","--------------------------------------------------------------------------------\n","5. [Rosacea] text_length: 58\n","   query: 주사는 어떤 종류의 만성 피부 질환인가요?...\n","   text: 주사(酒齄, rosacea), 주사비(酒齄鼻), 빨간 코, 딸기코는 얼굴에 감염되는 만성 피부 질환이다.\n","--------------------------------------------------------------------------------\n","6. [Seborrheic Dermatitis] text_length: 60\n","   query: 지루성 피부염 진단은 어떻게 하나요?...\n","   text: 증상 부위의 위치와 모양 의사들은 증상이 나타난 피부의 위치와 모양에 근거하여 지루 피부염 진단을 내립니다.\n","--------------------------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["import json\n","\n","def remove_short_texts(input_file, output_file, max_length=50):\n","    \"\"\"JSONL 파일에서 text_length가 지정값 이하인 샘플들을 제거\"\"\"\n","\n","    removed_count = 0\n","    kept_count = 0\n","\n","    with open(input_file, 'r', encoding='utf-8') as infile, \\\n","         open(output_file, 'w', encoding='utf-8') as outfile:\n","\n","        for line in infile:\n","            data = json.loads(line.strip())\n","            text_length = data['golden']['text_length']\n","\n","            # text_length가 50 초과인 것만 유지\n","            if text_length > max_length:\n","                outfile.write(json.dumps(data, ensure_ascii=False) + '\\n')\n","                kept_count += 1\n","            else:\n","                removed_count += 1\n","\n","    # 결과 출력\n","    print(f\"=== 필터링 완료 ===\")\n","    print(f\"제거된 샘플: {removed_count}개 (text_length <= {max_length})\")\n","    print(f\"유지된 샘플: {kept_count}개 (text_length > {max_length})\")\n","    print(f\"결과 파일: {output_file}\")\n","\n","# 실행\n","if __name__ == \"__main__\":\n","    input_file = \"raft_samples.jsonl\"      # 원본 파일\n","    output_file = \"raft_samples_filtered.jsonl\"  # 필터링된 파일\n","\n","    remove_short_texts(input_file, output_file, 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VGJBCOKhrwnQ","executionInfo":{"status":"ok","timestamp":1764051854805,"user_tz":-540,"elapsed":289,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"36bf92bf-dd0e-4c3e-f418-aed6f44a3a36"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["=== 필터링 완료 ===\n","제거된 샘플: 220개 (text_length <= 50)\n","유지된 샘플: 4240개 (text_length > 50)\n","결과 파일: raft_samples_filtered.jsonl\n"]}]},{"cell_type":"code","source":["import json\n","from collections import Counter\n","\n","def count_labels(jsonl_file):\n","    \"\"\"JSONL 파일에서 golden label들을 카운트하는 함수\"\"\"\n","\n","    label_counts = Counter()\n","\n","    with open(jsonl_file, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            data = json.loads(line.strip())\n","            label = data['golden']['label']\n","            label_counts[label] += 1\n","\n","    # 결과 출력\n","    print(f\"총 샘플 수: {sum(label_counts.values())}\")\n","    print(f\"라벨 종류: {len(label_counts)}\")\n","    print(\"\\n라벨별 개수:\")\n","    print(\"-\" * 40)\n","\n","    for label, count in label_counts.most_common():\n","        print(f\"{label}: {count}개\")\n","\n","    return label_counts\n","\n","# 실행\n","if __name__ == \"__main__\":\n","    jsonl_file = \"raft_samples_filtered.jsonl\"  # 파일명을 실제 파일로 변경\n","    count_labels(jsonl_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764051955466,"user_tz":-540,"elapsed":109,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"71914ae3-9371-4710-fda5-d82738184c91","id":"lriwkxrAsIBn"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["총 샘플 수: 4240\n","라벨 종류: 5\n","\n","라벨별 개수:\n","----------------------------------------\n","Acne: 1160개\n","Atopic Dermatitis: 960개\n","Psoriasis: 860개\n","Seborrheic Dermatitis: 640개\n","Rosacea: 620개\n"]}]},{"cell_type":"markdown","source":["##**번역 시도**"],"metadata":{"id":"2V6-UuFD-7yD"}},{"cell_type":"code","source":["!pip install torch transformers tqdm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tYek3-pu-_jC","executionInfo":{"status":"ok","timestamp":1764056901700,"user_tz":-540,"elapsed":4487,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"8080388b-e651-4c70-e760-592a1efdde82"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"]}]},{"cell_type":"code","source":["import json\n","import torch\n","from transformers import MarianMTModel, MarianTokenizer\n","from tqdm import tqdm\n","import gc\n","\n","def setup_translation_model():\n","    \"\"\"번역 모델 설정\"\"\"\n","    model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n","\n","    # GPU 사용 가능 여부 확인\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(f\"사용 디바이스: {device}\")\n","\n","    # 모델과 토크나이저 로드\n","    tokenizer = MarianTokenizer.from_pretrained(model_name)\n","    model = MarianMTModel.from_pretrained(model_name)\n","    model.to(device)\n","\n","    return model, tokenizer, device\n","\n","def translate_text(text, model, tokenizer, device, max_length=512):\n","    \"\"\"단일 텍스트 번역\"\"\"\n","    if not text or text.strip() == \"\":\n","        return text\n","\n","    try:\n","        # 텍스트가 너무 길면 청크로 분할\n","        if len(text) > max_length:\n","            return translate_long_text(text, model, tokenizer, device, max_length)\n","\n","        # 토크나이징\n","        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n","        inputs = {key: value.to(device) for key, value in inputs.items()}\n","\n","        # 번역 생성\n","        with torch.no_grad():\n","            translated = model.generate(**inputs, max_length=max_length, num_beams=4, early_stopping=True)\n","\n","        # 디코딩\n","        translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n","        return translated_text\n","\n","    except Exception as e:\n","        print(f\"번역 오류: {text[:50]}... -> {str(e)}\")\n","        return text  # 오류 시 원본 반환\n","\n","def translate_long_text(text, model, tokenizer, device, max_length=512):\n","    \"\"\"긴 텍스트를 청크로 나누어 번역\"\"\"\n","    sentences = text.split('. ')\n","    translated_chunks = []\n","    current_chunk = \"\"\n","\n","    for sentence in sentences:\n","        if len(current_chunk + sentence) < max_length:\n","            current_chunk += sentence + \". \"\n","        else:\n","            if current_chunk:\n","                translated_chunk = translate_text(current_chunk.strip(), model, tokenizer, device, max_length)\n","                translated_chunks.append(translated_chunk)\n","            current_chunk = sentence + \". \"\n","\n","    # 마지막 청크 처리\n","    if current_chunk:\n","        translated_chunk = translate_text(current_chunk.strip(), model, tokenizer, device, max_length)\n","        translated_chunks.append(translated_chunk)\n","\n","    return \" \".join(translated_chunks)\n","\n","def translate_sample(sample, model, tokenizer, device):\n","    \"\"\"단일 샘플의 모든 한국어 필드 번역\"\"\"\n","    translated_sample = sample.copy()\n","\n","    # query 번역\n","    if 'query' in sample:\n","        translated_sample['query'] = translate_text(sample['query'], model, tokenizer, device)\n","\n","    # golden 필드 번역\n","    if 'golden' in sample:\n","        golden = sample['golden'].copy()\n","\n","        if 'text' in golden:\n","            golden['text'] = translate_text(golden['text'], model, tokenizer, device)\n","\n","        if 'title' in golden:\n","            golden['title'] = translate_text(golden['title'], model, tokenizer, device)\n","\n","        # text_length 업데이트\n","        if 'text' in golden:\n","            golden['text_length'] = len(golden['text'])\n","\n","        translated_sample['golden'] = golden\n","\n","    # hard_negatives 번역\n","    if 'hard_negatives' in sample:\n","        translated_hard_negatives = []\n","\n","        for neg in sample['hard_negatives']:\n","            translated_neg = neg.copy()\n","\n","            if 'text' in neg:\n","                translated_neg['text'] = translate_text(neg['text'], model, tokenizer, device)\n","\n","            if 'title' in neg:\n","                translated_neg['title'] = translate_text(neg['title'], model, tokenizer, device)\n","\n","            # text_length 업데이트\n","            if 'text' in translated_neg:\n","                translated_neg['text_length'] = len(translated_neg['text'])\n","\n","            translated_hard_negatives.append(translated_neg)\n","\n","        translated_sample['hard_negatives'] = translated_hard_negatives\n","\n","    # easy_negative 번역\n","    if 'easy_negative' in sample:\n","        easy_neg = sample['easy_negative'].copy()\n","\n","        if 'text' in easy_neg:\n","            easy_neg['text'] = translate_text(easy_neg['text'], model, tokenizer, device)\n","\n","        if 'title' in easy_neg:\n","            easy_neg['title'] = translate_text(easy_neg['title'], model, tokenizer, device)\n","\n","        # text_length 업데이트\n","        if 'text' in easy_neg:\n","            easy_neg['text_length'] = len(easy_neg['text'])\n","\n","        translated_sample['easy_negative'] = easy_neg\n","\n","    return translated_sample\n","\n","def translate_jsonl_file(input_file, output_file, batch_size=16):\n","    \"\"\"JSONL 파일 전체 번역\"\"\"\n","\n","    # 모델 설정\n","    print(\"번역 모델 로딩 중...\")\n","    model, tokenizer, device = setup_translation_model()\n","\n","    # 전체 샘플 수 확인\n","    total_samples = 0\n","    with open(input_file, 'r', encoding='utf-8') as f:\n","        for _ in f:\n","            total_samples += 1\n","\n","    print(f\"총 {total_samples}개 샘플 번역 시작...\")\n","\n","    # 번역 및 저장\n","    with open(input_file, 'r', encoding='utf-8') as infile, \\\n","         open(output_file, 'w', encoding='utf-8') as outfile:\n","\n","        batch = []\n","        processed = 0\n","\n","        for line in tqdm(infile, total=total_samples, desc=\"번역 진행\"):\n","            sample = json.loads(line.strip())\n","            batch.append(sample)\n","\n","            # 배치 처리\n","            if len(batch) >= batch_size:\n","                translated_batch = process_batch(batch, model, tokenizer, device)\n","\n","                for translated_sample in translated_batch:\n","                    outfile.write(json.dumps(translated_sample, ensure_ascii=False) + '\\n')\n","\n","                processed += len(batch)\n","                batch = []\n","\n","                # 메모리 정리\n","                if processed % (batch_size * 10) == 0:\n","                    gc.collect()\n","                    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n","                    print(f\"진행률: {processed}/{total_samples} ({processed/total_samples*100:.1f}%)\")\n","\n","        # 남은 배치 처리\n","        if batch:\n","            translated_batch = process_batch(batch, model, tokenizer, device)\n","            for translated_sample in translated_batch:\n","                outfile.write(json.dumps(translated_sample, ensure_ascii=False) + '\\n')\n","\n","    print(f\"번역 완료! 결과 파일: {output_file}\")\n","\n","def process_batch(batch, model, tokenizer, device):\n","    \"\"\"배치 단위 처리\"\"\"\n","    translated_batch = []\n","\n","    for sample in batch:\n","        try:\n","            translated_sample = translate_sample(sample, model, tokenizer, device)\n","            translated_batch.append(translated_sample)\n","        except Exception as e:\n","            print(f\"샘플 번역 오류: {str(e)}\")\n","            translated_batch.append(sample)  # 오류 시 원본 유지\n","\n","    return translated_batch\n","\n","def validate_translation(original_file, translated_file, sample_size=10):\n","    \"\"\"번역 결과 검증 (샘플링)\"\"\"\n","    print(f\"\\n번역 품질 검증 (샘플 {sample_size}개)...\")\n","\n","    original_samples = []\n","    translated_samples = []\n","\n","    # 원본 로드\n","    with open(original_file, 'r', encoding='utf-8') as f:\n","        for i, line in enumerate(f):\n","            if i >= sample_size:\n","                break\n","            original_samples.append(json.loads(line.strip()))\n","\n","    # 번역본 로드\n","    with open(translated_file, 'r', encoding='utf-8') as f:\n","        for i, line in enumerate(f):\n","            if i >= sample_size:\n","                break\n","            translated_samples.append(json.loads(line.strip()))\n","\n","    # 비교 출력\n","    for i in range(min(len(original_samples), len(translated_samples))):\n","        print(f\"\\n=== 샘플 {i+1} ===\")\n","        print(f\"원본 쿼리: {original_samples[i].get('query', '')[:100]}...\")\n","        print(f\"번역 쿼리: {translated_samples[i].get('query', '')[:100]}...\")\n","        print(f\"원본 텍스트: {original_samples[i]['golden']['text'][:100]}...\")\n","        print(f\"번역 텍스트: {translated_samples[i]['golden']['text'][:100]}...\")\n","        print(\"-\" * 50)\n","\n","def main():\n","    # 파일 경로 설정\n","    input_file = \"raft_train_dataset_final.jsonl\"     # 원본 한국어 파일\n","    output_file = \"english_raft_dataset.jsonl\"   # 번역된 영어 파일\n","\n","    # 번역 실행\n","    translate_jsonl_file(input_file, output_file, batch_size=8)  # GPU 메모리에 따라 조정\n","\n","    # 품질 검증\n","    validate_translation(input_file, output_file, sample_size=5)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oCRsU56h_Cy1","executionInfo":{"status":"ok","timestamp":1764077157055,"user_tz":-540,"elapsed":15636926,"user":{"displayName":"이준","userId":"07774062018208294232"}},"outputId":"8ea9f3bf-f6a5-4119-f287-86df6bb3c659"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["번역 모델 로딩 중...\n","사용 디바이스: cuda\n","총 4240개 샘플 번역 시작...\n"]},{"output_type":"stream","name":"stderr","text":["번역 진행:   2%|▏         | 80/4240 [05:24<4:19:42,  3.75s/it]"]},{"output_type":"stream","name":"stdout","text":["진행률: 80/4240 (1.9%)\n"]},{"output_type":"stream","name":"stderr","text":["번역 진행:   4%|▍         | 160/4240 [10:32<3:56:59,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":["진행률: 160/4240 (3.8%)\n"]},{"output_type":"stream","name":"stderr","text":["번역 진행:   6%|▌         | 240/4240 [16:20<4:32:26,  4.09s/it]"]},{"output_type":"stream","name":"stdout","text":["진행률: 240/4240 (5.7%)\n"]},{"output_type":"stream","name":"stderr","text":["번역 진행:   8%|▊         | 320/4240 [22:00<4:28:52,  4.12s/it]"]},{"output_type":"stream","name":"stdout","text":["진행률: 320/4240 (7.5%)\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n"]},{"output_type":"stream","name":"stderr","text":["번역 진행: 100%|██████████| 4240/4240 [4:20:35<00:00,  3.69s/it]"]},{"output_type":"stream","name":"stdout","text":["번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","진행률: 400/4240 (9.4%)\n","진행률: 480/4240 (11.3%)\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","진행률: 560/4240 (13.2%)\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","진행률: 640/4240 (15.1%)\n","진행률: 720/4240 (17.0%)\n","진행률: 800/4240 (18.9%)\n","진행률: 880/4240 (20.8%)\n","진행률: 960/4240 (22.6%)\n","진행률: 1040/4240 (24.5%)\n","진행률: 1120/4240 (26.4%)\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","진행률: 1200/4240 (28.3%)\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","진행률: 1280/4240 (30.2%)\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","진행률: 1360/4240 (32.1%)\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","진행률: 1440/4240 (34.0%)\n","진행률: 1520/4240 (35.8%)\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","진행률: 1600/4240 (37.7%)\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","진행률: 1680/4240 (39.6%)\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","진행률: 1760/4240 (41.5%)\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","진행률: 1840/4240 (43.4%)\n","진행률: 1920/4240 (45.3%)\n","진행률: 2000/4240 (47.2%)\n","진행률: 2080/4240 (49.1%)\n","진행률: 2160/4240 (50.9%)\n","진행률: 2240/4240 (52.8%)\n","진행률: 2320/4240 (54.7%)\n","진행률: 2400/4240 (56.6%)\n","진행률: 2480/4240 (58.5%)\n","진행률: 2560/4240 (60.4%)\n","진행률: 2640/4240 (62.3%)\n","진행률: 2720/4240 (64.2%)\n","진행률: 2800/4240 (66.0%)\n","진행률: 2880/4240 (67.9%)\n","진행률: 2960/4240 (69.8%)\n","진행률: 3040/4240 (71.7%)\n","진행률: 3120/4240 (73.6%)\n","진행률: 3200/4240 (75.5%)\n","진행률: 3280/4240 (77.4%)\n","진행률: 3360/4240 (79.2%)\n","진행률: 3440/4240 (81.1%)\n","진행률: 3520/4240 (83.0%)\n","진행률: 3600/4240 (84.9%)\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","진행률: 3680/4240 (86.8%)\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","진행률: 3760/4240 (88.7%)\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","진행률: 3840/4240 (90.6%)\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","진행률: 3920/4240 (92.5%)\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","진행률: 4000/4240 (94.3%)\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","진행률: 4080/4240 (96.2%)\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","번역 오류: 과산화 벤조일 피부 건조 의복과 체모의 탈색 가능성 알레르기 반응(드묾) 에리스로마이신이나... -> maximum recursion depth exceeded\n","진행률: 4160/4240 (98.1%)\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 은 물질 제거(경구 복용) 이소트레티노인 태아 발달에 해를 미칠 수 있음 혈액 세포, 간,... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","번역 오류: 글리콜산 따가움 경미한 자극 처방 제품에 추가해 사용되나 더 이상 흔하게 사용되지 않는 크... -> maximum recursion depth exceeded\n","진행률: 4240/4240 (100.0%)\n","번역 완료! 결과 파일: english_raft_dataset.jsonl\n","\n","번역 품질 검증 (샘플 5개)...\n","\n","=== 샘플 1 ===\n","원본 쿼리: 여드름이 생기는 가장 기본적인 이유가 궁금해요. 호르몬, 피지, 세균이 서로 어떻게 작용해서 여드름이 되는 건가요?...\n","번역 쿼리: I'm curious about the basic reasons why acne occurs: how hormones, Fiji and bacteria act on each oth...\n","원본 텍스트: 여드름은 모낭(모발이 자라는 피부의 구멍)의 염증을 일으키는 호르몬, 피지, 세균 간의 상호작용에 의해 발생합니다. 여드름은 많은 유형의 피부 이상(병변)을 특징으로 합니다. 이들...\n","번역 텍스트: The acne is caused by an inflammation of the skin follicles (the skin hole in the hair) interaction ...\n","--------------------------------------------------\n","\n","=== 샘플 2 ===\n","원본 쿼리: 블랙헤드랑 패립종(화이트헤드)은 뭐가 다른 거예요?...\n","번역 쿼리: What's the difference between the blackhead and the whitehead?...\n","원본 텍스트: 여드름은 모낭(모발이 자라는 피부의 구멍)의 염증을 일으키는 호르몬, 피지, 세균 간의 상호작용에 의해 발생합니다. 여드름은 많은 유형의 피부 이상(병변)을 특징으로 합니다. 이들...\n","번역 텍스트: The acne is caused by an inflammation of the skin follicles (the skin hole in the hair) interaction ...\n","--------------------------------------------------\n","\n","=== 샘플 3 ===\n","원본 쿼리: 뾰루지, 구진, 농포, 결절, 낭, 농양 같은 용어들이 너무 어려워요. 각각 피부에 어떻게 나타나는 건지 쉽게 설명해 줄 수 있나요?...\n","번역 쿼리: And the terms are so hard to understand that each one of them is showing up on the skin....\n","원본 텍스트: 여드름은 모낭(모발이 자라는 피부의 구멍)의 염증을 일으키는 호르몬, 피지, 세균 간의 상호작용에 의해 발생합니다. 여드름은 많은 유형의 피부 이상(병변)을 특징으로 합니다. 이들...\n","번역 텍스트: The acne is caused by an inflammation of the skin follicles (the skin hole in the hair) interaction ...\n","--------------------------------------------------\n","\n","=== 샘플 4 ===\n","원본 쿼리: 낭이랑 농양은 둘 다 고름이 찬 주머니라고 했는데, 농양이 '뿌리가 더 깊은 편'이라는 건 무슨 뜻인가요?...\n","번역 쿼리: What do you mean when you think of both romantic and abscess as a pussy pocket?...\n","원본 텍스트: 여드름은 모낭(모발이 자라는 피부의 구멍)의 염증을 일으키는 호르몬, 피지, 세균 간의 상호작용에 의해 발생합니다. 여드름은 많은 유형의 피부 이상(병변)을 특징으로 합니다. 이들...\n","번역 텍스트: The acne is caused by an inflammation of the skin follicles (the skin hole in the hair) interaction ...\n","--------------------------------------------------\n","\n","=== 샘플 5 ===\n","원본 쿼리: 여드름이 생기면 왜 다양한 모양으로 나타나는 건가요? (크기, 중증도, 깊이의 차이에 대한 질문)...\n","번역 쿼리: Why does a pimple come in all sorts of shapes?...\n","원본 텍스트: 여드름은 모낭(모발이 자라는 피부의 구멍)의 염증을 일으키는 호르몬, 피지, 세균 간의 상호작용에 의해 발생합니다. 여드름은 많은 유형의 피부 이상(병변)을 특징으로 합니다. 이들...\n","번역 텍스트: The acne is caused by an inflammation of the skin follicles (the skin hole in the hair) interaction ...\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}